{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ed29127a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2118819c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Generate synthetic data\n",
    "np.random.seed(42)\n",
    "X = np.random.rand(1000, 1)\n",
    "y_true = 5 * X + 4.5 + 0.1 * np.random.randn(1000, 1)\n",
    "\n",
    "# Add a bias term to X\n",
    "X_b = np.c_[np.ones((1000, 1)), X]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e6e6bb99",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Initializations\n",
    "learning_rate = 0.01\n",
    "n_epochs = 1000  # Increase the maximum number of epochs\n",
    "batch_size = 10\n",
    "m = len(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c2e6012a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Function to calculate mean squared error\n",
    "def mse(y_true, y_pred):\n",
    "    return np.mean((y_true - y_pred) ** 2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "afb1adf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Batch Gradient Descent (BGD)\n",
    "def batch_gradient_descent(X_b, y_true, learning_rate, n_epochs, tol=1e-4):\n",
    "    w = np.random.randn(2, 1)\n",
    "    prev_loss = float('inf')\n",
    "    \n",
    "    for epoch in range(n_epochs):\n",
    "        gradients = -2/m * X_b.T.dot(y_true - X_b.dot(w))\n",
    "        w -= learning_rate * gradients\n",
    "        y_pred = X_b.dot(w)\n",
    "        loss = mse(y_true, y_pred)\n",
    "        print(f\"Epoch {epoch}, Loss: {loss}\")\n",
    "        \n",
    "        # Check convergence based on change in loss\n",
    "        if abs(prev_loss - loss) < tol:\n",
    "            break\n",
    "        \n",
    "        prev_loss = loss\n",
    "    \n",
    "    return w.flatten(), epoch + 1  # Return optimal weights and number of epochs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0177497e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Stochastic Gradient Descent (SGD)\n",
    "def stochastic_gradient_descent(X_b, y_true, learning_rate, n_epochs, tol=1e-4):\n",
    "    w = np.random.randn(2, 1)\n",
    "    prev_loss = float('inf')\n",
    "    \n",
    "    for epoch in range(n_epochs):\n",
    "        for i in range(m):\n",
    "            random_index = random.randint(0, m - 1)\n",
    "            xi = X_b[random_index:random_index+1]\n",
    "            yi = y_true[random_index:random_index+1]\n",
    "            gradients = -2 * xi.T.dot(yi - xi.dot(w))\n",
    "            w -= learning_rate * gradients\n",
    "            y_pred = X_b.dot(w)\n",
    "            loss = mse(y_true, y_pred)\n",
    "        \n",
    "        print(f\"Epoch {epoch}, Loss: {loss}\")\n",
    "        \n",
    "        # Check convergence based on change in loss\n",
    "        if abs(prev_loss - loss) < tol:\n",
    "            break\n",
    "        \n",
    "        prev_loss = loss\n",
    "    \n",
    "    return w.flatten(), epoch + 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "53a64dfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Mini-Batch Gradient Descent (MBGD)\n",
    "def mini_batch_gradient_descent(X_b, y_true, learning_rate, n_epochs, batch_size, tol=1e-4):\n",
    "    w = np.random.randn(2, 1)\n",
    "    prev_loss = float('inf')\n",
    "    \n",
    "    for epoch in range(n_epochs):\n",
    "        for i in range(0, m, batch_size):\n",
    "            xi = X_b[i:i+batch_size]\n",
    "            yi = y_true[i:i+batch_size]\n",
    "            gradients = -2/batch_size * xi.T.dot(yi - xi.dot(w))\n",
    "            w -= learning_rate * gradients\n",
    "            y_pred = X_b.dot(w)\n",
    "            loss = mse(y_true, y_pred)\n",
    "        \n",
    "        print(f\"Epoch {epoch}, Loss: {loss}\")\n",
    "        \n",
    "        # Check convergence based on change in loss\n",
    "        if abs(prev_loss - loss) < tol:\n",
    "            break\n",
    "        \n",
    "        prev_loss = loss\n",
    "    \n",
    "    return w.flatten(), epoch + 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ee7a44ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 45.367359627044515\n",
      "Epoch 1, Loss: 43.12252411572938\n",
      "Epoch 2, Loss: 40.98918946499093\n",
      "Epoch 3, Loss: 38.96181634611491\n",
      "Epoch 4, Loss: 37.03514062549209\n",
      "Epoch 5, Loss: 35.20415969285507\n",
      "Epoch 6, Loss: 33.464119468731894\n",
      "Epoch 7, Loss: 31.810502057372705\n",
      "Epoch 8, Loss: 30.239014013082148\n",
      "Epoch 9, Loss: 28.74557518948339\n",
      "Epoch 10, Loss: 27.32630814275357\n",
      "Epoch 11, Loss: 25.977528061309304\n",
      "Epoch 12, Loss: 24.695733195787877\n",
      "Epoch 13, Loss: 23.47759576446955\n",
      "Epoch 14, Loss: 22.319953310520752\n",
      "Epoch 15, Loss: 21.219800488611668\n",
      "Epoch 16, Loss: 20.174281259576787\n",
      "Epoch 17, Loss: 19.180681472846715\n",
      "Epoch 18, Loss: 18.23642181738668\n",
      "Epoch 19, Loss: 17.339051122834213\n",
      "Epoch 20, Loss: 16.48623999343805\n",
      "Epoch 21, Loss: 15.675774758264573\n",
      "Epoch 22, Loss: 14.905551721959545\n",
      "Epoch 23, Loss: 14.173571701133495\n",
      "Epoch 24, Loss: 13.477934832180871\n",
      "Epoch 25, Loss: 12.816835637048069\n",
      "Epoch 26, Loss: 12.18855833413537\n",
      "Epoch 27, Loss: 11.591472382154501\n",
      "Epoch 28, Loss: 11.02402824536845\n",
      "Epoch 29, Loss: 10.484753369215305\n",
      "Epoch 30, Loss: 9.972248355864092\n",
      "Epoch 31, Loss: 9.485183329770019\n",
      "Epoch 32, Loss: 9.022294483789821\n",
      "Epoch 33, Loss: 8.582380796887044\n",
      "Epoch 34, Loss: 8.16430091490252\n",
      "Epoch 35, Loss: 7.766970186288976\n",
      "Epoch 36, Loss: 7.389357845111141\n",
      "Epoch 37, Loss: 7.030484333995096\n",
      "Epoch 38, Loss: 6.689418760074199\n",
      "Epoch 39, Loss: 6.36527647732427\n",
      "Epoch 40, Loss: 6.057216789008986\n",
      "Epoch 41, Loss: 5.764440764268376\n",
      "Epoch 42, Loss: 5.486189163179764\n",
      "Epoch 43, Loss: 5.221740464902206\n",
      "Epoch 44, Loss: 4.970408993783232\n",
      "Epoch 45, Loss: 4.731543138561071\n",
      "Epoch 46, Loss: 4.504523660037386\n",
      "Epoch 47, Loss: 4.288762082825237\n",
      "Epoch 48, Loss: 4.083699166995431\n",
      "Epoch 49, Loss: 3.888803455651883\n",
      "Epoch 50, Loss: 3.703569894663784\n",
      "Epoch 51, Loss: 3.527518520969842\n",
      "Epoch 52, Loss: 3.3601932160479002\n",
      "Epoch 53, Loss: 3.2011605213125134\n",
      "Epoch 54, Loss: 3.0500085123638607\n",
      "Epoch 55, Loss: 2.9063457291642694\n",
      "Epoch 56, Loss: 2.7698001593638435\n",
      "Epoch 57, Loss: 2.6400182721347356\n",
      "Epoch 58, Loss: 2.516664100004773\n",
      "Epoch 59, Loss: 2.399418366305839\n",
      "Epoch 60, Loss: 2.28797765597082\n",
      "Epoch 61, Loss: 2.182053627525591\n",
      "Epoch 62, Loss: 2.0813722642294334\n",
      "Epoch 63, Loss: 1.9856731624189912\n",
      "Epoch 64, Loss: 1.894708855207479\n",
      "Epoch 65, Loss: 1.8082441697826797\n",
      "Epoch 66, Loss: 1.7260556166345589\n",
      "Epoch 67, Loss: 1.6479308091261924\n",
      "Epoch 68, Loss: 1.5736679119005637\n",
      "Epoch 69, Loss: 1.5030751166906524\n",
      "Epoch 70, Loss: 1.435970144171407\n",
      "Epoch 71, Loss: 1.37217977055985\n",
      "Epoch 72, Loss: 1.3115393777337958\n",
      "Epoch 73, Loss: 1.2538925257007987\n",
      "Epoch 74, Loss: 1.1990905463069408\n",
      "Epoch 75, Loss: 1.1469921571302804\n",
      "Epoch 76, Loss: 1.0974630945561652\n",
      "Epoch 77, Loss: 1.0503757650814618\n",
      "Epoch 78, Loss: 1.0056089139420756\n",
      "Epoch 79, Loss: 0.9630473102031457\n",
      "Epoch 80, Loss: 0.9225814474940337\n",
      "Epoch 81, Loss: 0.884107259610872\n",
      "Epoch 82, Loss: 0.8475258502480615\n",
      "Epoch 83, Loss: 0.8127432361567591\n",
      "Epoch 84, Loss: 0.7796701030633337\n",
      "Epoch 85, Loss: 0.7482215737138449\n",
      "Epoch 86, Loss: 0.7183169874421321\n",
      "Epoch 87, Loss: 0.6898796906890212\n",
      "Epoch 88, Loss: 0.6628368379285839\n",
      "Epoch 89, Loss: 0.6371192024844351\n",
      "Epoch 90, Loss: 0.6126609967447201\n",
      "Epoch 91, Loss: 0.5893997013088713\n",
      "Epoch 92, Loss: 0.5672759026223946\n",
      "Epoch 93, Loss: 0.546233138678\n",
      "Epoch 94, Loss: 0.5262177523823388\n",
      "Epoch 95, Loss: 0.5071787522075178\n",
      "Epoch 96, Loss: 0.48906767976548354\n",
      "Epoch 97, Loss: 0.4718384839613417\n",
      "Epoch 98, Loss: 0.4554474013987699\n",
      "Epoch 99, Loss: 0.43985284272692393\n",
      "Epoch 100, Loss: 0.4250152846336521\n",
      "Epoch 101, Loss: 0.4108971672045199\n",
      "Epoch 102, Loss: 0.3974627963810574\n",
      "Epoch 103, Loss: 0.38467825126490995\n",
      "Epoch 104, Loss: 0.37251129602713856\n",
      "Epoch 105, Loss: 0.3609312961938902\n",
      "Epoch 106, Loss: 0.34990913909101395\n",
      "Epoch 107, Loss: 0.33941715824100993\n",
      "Epoch 108, Loss: 0.3294290615159572\n",
      "Epoch 109, Loss: 0.31991986285981855\n",
      "Epoch 110, Loss: 0.31086581740280195\n",
      "Epoch 111, Loss: 0.3022443597992515\n",
      "Epoch 112, Loss: 0.2940340456289307\n",
      "Epoch 113, Loss: 0.28621449570950386\n",
      "Epoch 114, Loss: 0.2787663431755841\n",
      "Epoch 115, Loss: 0.2716711831869088\n",
      "Epoch 116, Loss: 0.2649115251350261\n",
      "Epoch 117, Loss: 0.258470747224362\n",
      "Epoch 118, Loss: 0.25233305330971123\n",
      "Epoch 119, Loss: 0.24648343187805488\n",
      "Epoch 120, Loss: 0.2409076170681668\n",
      "Epoch 121, Loss: 0.2355920516267772\n",
      "Epoch 122, Loss: 0.23052385170508222\n",
      "Epoch 123, Loss: 0.22569077340417162\n",
      "Epoch 124, Loss: 0.22108118098248677\n",
      "Epoch 125, Loss: 0.21668401664273887\n",
      "Epoch 126, Loss: 0.21248877181982145\n",
      "Epoch 127, Loss: 0.20848545989514453\n",
      "Epoch 128, Loss: 0.20466459026652636\n",
      "Epoch 129, Loss: 0.20101714370630164\n",
      "Epoch 130, Loss: 0.19753454894364\n",
      "Epoch 131, Loss: 0.1942086604102638\n",
      "Epoch 132, Loss: 0.1910317370917617\n",
      "Epoch 133, Loss: 0.1879964224295736\n",
      "Epoch 134, Loss: 0.1850957252214499\n",
      "Epoch 135, Loss: 0.18232300147077876\n",
      "Epoch 136, Loss: 0.1796719371376445\n",
      "Epoch 137, Loss: 0.17713653174681546\n",
      "Epoch 138, Loss: 0.17471108281009007\n",
      "Epoch 139, Loss: 0.172390171022546\n",
      "Epoch 140, Loss: 0.17016864619424013\n",
      "Epoch 141, Loss: 0.16804161388082556\n",
      "Epoch 142, Loss: 0.1660044226783626\n",
      "Epoch 143, Loss: 0.16405265214932513\n",
      "Epoch 144, Loss: 0.16218210134844577\n",
      "Epoch 145, Loss: 0.1603887779185984\n",
      "Epoch 146, Loss: 0.15866888772840018\n",
      "Epoch 147, Loss: 0.15701882502461875\n",
      "Epoch 148, Loss: 0.15543516307380914\n",
      "Epoch 149, Loss: 0.15391464526887683\n",
      "Epoch 150, Loss: 0.1524541766774671\n",
      "Epoch 151, Loss: 0.15105081601023257\n",
      "Epoch 152, Loss: 0.1497017679881175\n",
      "Epoch 153, Loss: 0.14840437608883755\n",
      "Epoch 154, Loss: 0.14715611565371495\n",
      "Epoch 155, Loss: 0.1459545873369666\n",
      "Epoch 156, Loss: 0.14479751088043338\n",
      "Epoch 157, Loss: 0.1436827191975811\n",
      "Epoch 158, Loss: 0.14260815275140856\n",
      "Epoch 159, Loss: 0.14157185421166305\n",
      "Epoch 160, Loss: 0.14057196337748445\n",
      "Epoch 161, Loss: 0.13960671235229355\n",
      "Epoch 162, Loss: 0.13867442095839289\n",
      "Epoch 163, Loss: 0.13777349237936953\n",
      "Epoch 164, Loss: 0.13690240901898415\n",
      "Epoch 165, Loss: 0.1360597285657908\n",
      "Epoch 166, Loss: 0.13524408025326648\n",
      "Epoch 167, Loss: 0.13445416130573734\n",
      "Epoch 168, Loss: 0.13368873356087188\n",
      "Epoch 169, Loss: 0.1329466202599685\n",
      "Epoch 170, Loss: 0.13222670299770153\n",
      "Epoch 171, Loss: 0.13152791882340417\n",
      "Epoch 172, Loss: 0.13084925748635895\n",
      "Epoch 173, Loss: 0.13018975881794295\n",
      "Epoch 174, Loss: 0.12954851024382738\n",
      "Epoch 175, Loss: 0.1289246444197712\n",
      "Epoch 176, Loss: 0.12831733698486777\n",
      "Epoch 177, Loss: 0.1277258044264111\n",
      "Epoch 178, Loss: 0.1271493020508341\n",
      "Epoch 179, Loss: 0.12658712205545108\n",
      "Epoch 180, Loss: 0.12603859169599585\n",
      "Epoch 181, Loss: 0.12550307154519574\n",
      "Epoch 182, Loss: 0.12497995383785962\n",
      "Epoch 183, Loss: 0.12446866089818169\n",
      "Epoch 184, Loss: 0.12396864364517635\n",
      "Epoch 185, Loss: 0.12347938017236257\n",
      "Epoch 186, Loss: 0.12300037439800923\n",
      "Epoch 187, Loss: 0.12253115478243597\n",
      "Epoch 188, Loss: 0.1220712731090381\n",
      "Epoch 189, Loss: 0.12162030332586928\n",
      "Epoch 190, Loss: 0.12117784044477468\n",
      "Epoch 191, Loss: 0.12074349949521411\n",
      "Epoch 192, Loss: 0.12031691453005913\n",
      "Epoch 193, Loss: 0.11989773768078131\n",
      "Epoch 194, Loss: 0.11948563825957845\n",
      "Epoch 195, Loss: 0.1190803019061068\n",
      "Epoch 196, Loss: 0.11868142977660251\n",
      "Epoch 197, Loss: 0.118288737773288\n",
      "Epoch 198, Loss: 0.11790195581205973\n",
      "Epoch 199, Loss: 0.11752082712655747\n",
      "Epoch 200, Loss: 0.11714510760680653\n",
      "Epoch 201, Loss: 0.11677456517071602\n",
      "Epoch 202, Loss: 0.1164089791667999\n",
      "Epoch 203, Loss: 0.1160481398065709\n",
      "Epoch 204, Loss: 0.11569184762513195\n",
      "Epoch 205, Loss: 0.11533991296856547\n",
      "Epoch 206, Loss: 0.11499215550678817\n",
      "Epoch 207, Loss: 0.11464840377060641\n",
      "Epoch 208, Loss: 0.11430849471177063\n",
      "Epoch 209, Loss: 0.11397227328488523\n",
      "Epoch 210, Loss: 0.11363959205008882\n",
      "Epoch 211, Loss: 0.11331031079547246\n",
      "Epoch 212, Loss: 0.11298429617825564\n",
      "Epoch 213, Loss: 0.11266142138378821\n",
      "Epoch 214, Loss: 0.11234156580149218\n",
      "Epoch 215, Loss: 0.1120246147169022\n",
      "Epoch 216, Loss: 0.1117104590190049\n",
      "Epoch 217, Loss: 0.11139899492211706\n",
      "Epoch 218, Loss: 0.11109012370158013\n",
      "Epoch 219, Loss: 0.11078375144258465\n",
      "Epoch 220, Loss: 0.11047978880147269\n",
      "Epoch 221, Loss: 0.11017815077889831\n",
      "Epoch 222, Loss: 0.10987875650425621\n",
      "Epoch 223, Loss: 0.10958152903081975\n",
      "Epoch 224, Loss: 0.1092863951410559\n",
      "Epoch 225, Loss: 0.10899328516161129\n",
      "Epoch 226, Loss: 0.10870213278748912\n",
      "Epoch 227, Loss: 0.1084128749149607\n",
      "Epoch 228, Loss: 0.10812545148277666\n",
      "Epoch 229, Loss: 0.10783980532126677\n",
      "Epoch 230, Loss: 0.10755588200893539\n",
      "Epoch 231, Loss: 0.10727362973618103\n",
      "Epoch 232, Loss: 0.106992999175785\n",
      "Epoch 233, Loss: 0.10671394335983468\n",
      "Epoch 234, Loss: 0.10643641756275926\n",
      "Epoch 235, Loss: 0.10616037919017667\n",
      "Epoch 236, Loss: 0.1058857876732614\n",
      "Epoch 237, Loss: 0.10561260436835977\n",
      "Epoch 238, Loss: 0.10534079246159148\n",
      "Epoch 239, Loss: 0.10507031687818993\n",
      "Epoch 240, Loss: 0.10480114419634617\n",
      "Epoch 241, Loss: 0.10453324256533188\n",
      "Epoch 242, Loss: 0.10426658162769\n",
      "Epoch 243, Loss: 0.10400113244528979\n",
      "Epoch 244, Loss: 0.10373686742905527\n",
      "Epoch 245, Loss: 0.1034737602721836\n",
      "Epoch 246, Loss: 0.10321178588668103\n",
      "Epoch 247, Loss: 0.10295092034305088\n",
      "Epoch 248, Loss: 0.1026911408129771\n",
      "Epoch 249, Loss: 0.10243242551485492\n",
      "Epoch 250, Loss: 0.10217475366202688\n",
      "Epoch 251, Loss: 0.10191810541358952\n",
      "Epoch 252, Loss: 0.10166246182764369\n",
      "Epoch 253, Loss: 0.10140780481686681\n",
      "Epoch 254, Loss: 0.10115411710629163\n",
      "Epoch 255, Loss: 0.10090138219318139\n",
      "Epoch 256, Loss: 0.10064958430889882\n",
      "Epoch 257, Loss: 0.10039870838266779\n",
      "Epoch 258, Loss: 0.1001487400071352\n",
      "Epoch 259, Loss: 0.09989966540564328\n",
      "Epoch 260, Loss: 0.09965147140112683\n",
      "Epoch 261, Loss: 0.09940414538655509\n",
      "Epoch 262, Loss: 0.09915767529684169\n",
      "Epoch 263, Loss: 0.09891204958214922\n",
      "Epoch 264, Loss: 0.0986672571825194\n",
      "Epoch 265, Loss: 0.09842328750376346\n",
      "Epoch 266, Loss: 0.09818013039454909\n",
      "Epoch 267, Loss: 0.09793777612462541\n",
      "Epoch 268, Loss: 0.09769621536412916\n",
      "Epoch 269, Loss: 0.09745543916391822\n",
      "Epoch 270, Loss: 0.09721543893688145\n",
      "Epoch 271, Loss: 0.0969762064401769\n",
      "Epoch 272, Loss: 0.09673773375835136\n",
      "Epoch 273, Loss: 0.09650001328729793\n",
      "Epoch 274, Loss: 0.09626303771901058\n",
      "Epoch 275, Loss: 0.09602680002709457\n",
      "Epoch 276, Loss: 0.09579129345299703\n",
      "Epoch 277, Loss: 0.09555651149292047\n",
      "Epoch 278, Loss: 0.09532244788538577\n",
      "Epoch 279, Loss: 0.09508909659941292\n",
      "Epoch 280, Loss: 0.09485645182328793\n",
      "Epoch 281, Loss: 0.0946245079538874\n",
      "Epoch 282, Loss: 0.09439325958653282\n",
      "Epoch 283, Loss: 0.09416270150534833\n",
      "Epoch 284, Loss: 0.09393282867409679\n",
      "Epoch 285, Loss: 0.09370363622747076\n",
      "Epoch 286, Loss: 0.09347511946281552\n",
      "Epoch 287, Loss: 0.09324727383226246\n",
      "Epoch 288, Loss: 0.09302009493525304\n",
      "Epoch 289, Loss: 0.09279357851143333\n",
      "Epoch 290, Loss: 0.09256772043390109\n",
      "Epoch 291, Loss: 0.09234251670278795\n",
      "Epoch 292, Loss: 0.09211796343915918\n",
      "Epoch 293, Loss: 0.09189405687921706\n",
      "Epoch 294, Loss: 0.09167079336879057\n",
      "Epoch 295, Loss: 0.09144816935809853\n",
      "Epoch 296, Loss: 0.09122618139677331\n",
      "Epoch 297, Loss: 0.0910048261291295\n",
      "Epoch 298, Loss: 0.09078410028966855\n",
      "Epoch 299, Loss: 0.09056400069880528\n",
      "Epoch 300, Loss: 0.09034452425880693\n",
      "Epoch 301, Loss: 0.09012566794993233\n",
      "Epoch 302, Loss: 0.08990742882676334\n",
      "Epoch 303, Loss: 0.08968980401471734\n",
      "Epoch 304, Loss: 0.08947279070673284\n",
      "Epoch 305, Loss: 0.08925638616011891\n",
      "Epoch 306, Loss: 0.08904058769356062\n",
      "Epoch 307, Loss: 0.08882539268427282\n",
      "Epoch 308, Loss: 0.08861079856529477\n",
      "Epoch 309, Loss: 0.08839680282291831\n",
      "Epoch 310, Loss: 0.08818340299424383\n",
      "Epoch 311, Loss: 0.0879705966648565\n",
      "Epoch 312, Loss: 0.08775838146661788\n",
      "Epoch 313, Loss: 0.08754675507556656\n",
      "Epoch 314, Loss: 0.08733571520992223\n",
      "Epoch 315, Loss: 0.0871252596281889\n",
      "Epoch 316, Loss: 0.0869153861273514\n",
      "Epoch 317, Loss: 0.08670609254116143\n",
      "Epoch 318, Loss: 0.08649737673850723\n",
      "Epoch 319, Loss: 0.08628923662186502\n",
      "Epoch 320, Loss: 0.08608167012582597\n",
      "Epoch 321, Loss: 0.08587467521569604\n",
      "Epoch 322, Loss: 0.0856682498861647\n",
      "Epoch 323, Loss: 0.0854623921600398\n",
      "Epoch 324, Loss: 0.08525710008704407\n",
      "Epoch 325, Loss: 0.08505237174267137\n",
      "Epoch 326, Loss: 0.0848482052270989\n",
      "Epoch 327, Loss: 0.08464459866415319\n",
      "Epoch 328, Loss: 0.0844415502003269\n",
      "Epoch 329, Loss: 0.08423905800384385\n",
      "Epoch 330, Loss: 0.08403712026377001\n",
      "Epoch 331, Loss: 0.0838357351891681\n",
      "Epoch 332, Loss: 0.08363490100829392\n",
      "Epoch 333, Loss: 0.08343461596783175\n",
      "Epoch 334, Loss: 0.08323487833216733\n",
      "Epoch 335, Loss: 0.08303568638269669\n",
      "Epoch 336, Loss: 0.08283703841716834\n",
      "Epoch 337, Loss: 0.08263893274905826\n",
      "Epoch 338, Loss: 0.08244136770697466\n",
      "Epoch 339, Loss: 0.08224434163409262\n",
      "Epoch 340, Loss: 0.0820478528876155\n",
      "Epoch 341, Loss: 0.08185189983826359\n",
      "Epoch 342, Loss: 0.08165648086978643\n",
      "Epoch 343, Loss: 0.08146159437850008\n",
      "Epoch 344, Loss: 0.08126723877284607\n",
      "Epoch 345, Loss: 0.08107341247297184\n",
      "Epoch 346, Loss: 0.08088011391033217\n",
      "Epoch 347, Loss: 0.08068734152730918\n",
      "Epoch 348, Loss: 0.08049509377685085\n",
      "Epoch 349, Loss: 0.08030336912212732\n",
      "Epoch 350, Loss: 0.08011216603620364\n",
      "Epoch 351, Loss: 0.07992148300172815\n",
      "Epoch 352, Loss: 0.07973131851063588\n",
      "Epoch 353, Loss: 0.07954167106386649\n",
      "Epoch 354, Loss: 0.07935253917109551\n",
      "Epoch 355, Loss: 0.07916392135047806\n",
      "Epoch 356, Loss: 0.07897581612840565\n",
      "Epoch 357, Loss: 0.07878822203927388\n",
      "Epoch 358, Loss: 0.07860113762526173\n",
      "Epoch 359, Loss: 0.07841456143612088\n",
      "Epoch 360, Loss: 0.07822849202897508\n",
      "Epoch 361, Loss: 0.07804292796812942\n",
      "Epoch 362, Loss: 0.07785786782488831\n",
      "Epoch 363, Loss: 0.07767331017738184\n",
      "Epoch 364, Loss: 0.0774892536104005\n",
      "Epoch 365, Loss: 0.0773056967152379\n",
      "Epoch 366, Loss: 0.07712263808954042\n",
      "Epoch 367, Loss: 0.07694007633716389\n",
      "Epoch 368, Loss: 0.07675801006803717\n",
      "Epoch 369, Loss: 0.07657643789803201\n",
      "Epoch 370, Loss: 0.07639535844883857\n",
      "Epoch 371, Loss: 0.07621477034784713\n",
      "Epoch 372, Loss: 0.07603467222803491\n",
      "Epoch 373, Loss: 0.07585506272785815\n",
      "Epoch 374, Loss: 0.07567594049114898\n",
      "Epoch 375, Loss: 0.07549730416701712\n",
      "Epoch 376, Loss: 0.07531915240975605\n",
      "Epoch 377, Loss: 0.07514148387875318\n",
      "Epoch 378, Loss: 0.07496429723840405\n",
      "Epoch 379, Loss: 0.07478759115803048\n",
      "Epoch 380, Loss: 0.07461136431180232\n",
      "Epoch 381, Loss: 0.07443561537866253\n",
      "Epoch 382, Loss: 0.07426034304225552\n",
      "Epoch 383, Loss: 0.07408554599085874\n",
      "Epoch 384, Loss: 0.07391122291731717\n",
      "Epoch 385, Loss: 0.0737373725189804\n",
      "Epoch 386, Loss: 0.07356399349764306\n",
      "Epoch 387, Loss: 0.07339108455948673\n",
      "Epoch 388, Loss: 0.0732186444150251\n",
      "Epoch 389, Loss: 0.07304667177905132\n",
      "Epoch 390, Loss: 0.07287516537058718\n",
      "Epoch 391, Loss: 0.07270412391283453\n",
      "Epoch 392, Loss: 0.07253354613312887\n",
      "Epoch 393, Loss: 0.07236343076289459\n",
      "Epoch 394, Loss: 0.072193776537602\n",
      "Epoch 395, Loss: 0.0720245821967263\n",
      "Epoch 396, Loss: 0.07185584648370777\n",
      "Epoch 397, Loss: 0.07168756814591384\n",
      "Epoch 398, Loss: 0.07151974593460254\n",
      "Epoch 399, Loss: 0.07135237860488709\n",
      "Epoch 400, Loss: 0.07118546491570218\n",
      "Epoch 401, Loss: 0.07101900362977134\n",
      "Epoch 402, Loss: 0.07085299351357542\n",
      "Epoch 403, Loss: 0.07068743333732233\n",
      "Epoch 404, Loss: 0.07052232187491768\n",
      "Epoch 405, Loss: 0.07035765790393693\n",
      "Epoch 406, Loss: 0.0701934402055979\n",
      "Epoch 407, Loss: 0.0700296675647345\n",
      "Epoch 408, Loss: 0.06986633876977151\n",
      "Epoch 409, Loss: 0.06970345261269978\n",
      "Epoch 410, Loss: 0.06954100788905282\n",
      "Epoch 411, Loss: 0.06937900339788347\n",
      "Epoch 412, Loss: 0.06921743794174184\n",
      "Epoch 413, Loss: 0.06905631032665359\n",
      "Epoch 414, Loss: 0.06889561936209936\n",
      "Epoch 415, Loss: 0.06873536386099417\n",
      "Epoch 416, Loss: 0.06857554263966786\n",
      "Epoch 417, Loss: 0.068416154517846\n",
      "Epoch 418, Loss: 0.06825719831863114\n",
      "Epoch 419, Loss: 0.06809867286848503\n",
      "Epoch 420, Loss: 0.06794057699721091\n",
      "Epoch 421, Loss: 0.06778290953793646\n",
      "Epoch 422, Loss: 0.06762566932709706\n",
      "Epoch 423, Loss: 0.06746885520441967\n",
      "Epoch 424, Loss: 0.06731246601290698\n",
      "Epoch 425, Loss: 0.06715650059882199\n",
      "Epoch 426, Loss: 0.06700095781167287\n",
      "Epoch 427, Loss: 0.06684583650419836\n",
      "Epoch 428, Loss: 0.06669113553235329\n",
      "Epoch 429, Loss: 0.06653685375529457\n",
      "Epoch 430, Loss: 0.06638299003536742\n",
      "Epoch 431, Loss: 0.0662295432380918\n",
      "Epoch 432, Loss: 0.06607651223214958\n",
      "Epoch 433, Loss: 0.06592389588937103\n",
      "Epoch 434, Loss: 0.0657716930847227\n",
      "Epoch 435, Loss: 0.06561990269629456\n",
      "Epoch 436, Loss: 0.06546852360528825\n",
      "Epoch 437, Loss: 0.06531755469600446\n",
      "Epoch 438, Loss: 0.06516699485583179\n",
      "Epoch 439, Loss: 0.06501684297523463\n",
      "Epoch 440, Loss: 0.06486709794774244\n",
      "Epoch 441, Loss: 0.06471775866993768\n",
      "Epoch 442, Loss: 0.06456882404144551\n",
      "Epoch 443, Loss: 0.06442029296492256\n",
      "Epoch 444, Loss: 0.0642721643460464\n",
      "Epoch 445, Loss: 0.06412443709350484\n",
      "Epoch 446, Loss: 0.06397711011898546\n",
      "Epoch 447, Loss: 0.06383018233716574\n",
      "Epoch 448, Loss: 0.06368365266570251\n",
      "Epoch 449, Loss: 0.06353752002522213\n",
      "Epoch 450, Loss: 0.06339178333931053\n",
      "Epoch 451, Loss: 0.06324644153450357\n",
      "Epoch 452, Loss: 0.06310149354027728\n",
      "Epoch 453, Loss: 0.0629569382890384\n",
      "Epoch 454, Loss: 0.06281277471611474\n",
      "Epoch 455, Loss: 0.06266900175974631\n",
      "Epoch 456, Loss: 0.06252561836107547\n",
      "Epoch 457, Loss: 0.06238262346413821\n",
      "Epoch 458, Loss: 0.062240016015855035\n",
      "Epoch 459, Loss: 0.06209779496602166\n",
      "Epoch 460, Loss: 0.06195595926730069\n",
      "Epoch 461, Loss: 0.06181450787521235\n",
      "Epoch 462, Loss: 0.061673439748125856\n",
      "Epoch 463, Loss: 0.0615327538472509\n",
      "Epoch 464, Loss: 0.06139244913662876\n",
      "Epoch 465, Loss: 0.06125252458312414\n",
      "Epoch 466, Loss: 0.06111297915641636\n",
      "Epoch 467, Loss: 0.06097381182899123\n",
      "Epoch 468, Loss: 0.060835021576132464\n",
      "Epoch 469, Loss: 0.06069660737591369\n",
      "Epoch 470, Loss: 0.060558568209190054\n",
      "Epoch 471, Loss: 0.06042090305959003\n",
      "Epoch 472, Loss: 0.06028361091350727\n",
      "Epoch 473, Loss: 0.06014669076009291\n",
      "Epoch 474, Loss: 0.060010141591246915\n",
      "Epoch 475, Loss: 0.059873962401610796\n",
      "Epoch 476, Loss: 0.05973815218855916\n",
      "Epoch 477, Loss: 0.059602709952192114\n",
      "Epoch 478, Loss: 0.059467634695327426\n",
      "Epoch 479, Loss: 0.05933292542349281\n",
      "Epoch 480, Loss: 0.05919858114491781\n",
      "Epoch 481, Loss: 0.05906460087052664\n",
      "Epoch 482, Loss: 0.058930983613930135\n",
      "Epoch 483, Loss: 0.058797728391418135\n",
      "Epoch 484, Loss: 0.058664834221952226\n",
      "Epoch 485, Loss: 0.05853230012715787\n",
      "Epoch 486, Loss: 0.05840012513131702\n",
      "Epoch 487, Loss: 0.05826830826136075\n",
      "Epoch 488, Loss: 0.05813684854686143\n",
      "Epoch 489, Loss: 0.058005745020025826\n",
      "Epoch 490, Loss: 0.05787499671568739\n",
      "Epoch 491, Loss: 0.057744602671298925\n",
      "Epoch 492, Loss: 0.05761456192692556\n",
      "Epoch 493, Loss: 0.057484873525237\n",
      "Epoch 494, Loss: 0.057355536511500785\n",
      "Epoch 495, Loss: 0.0572265499335746\n",
      "Epoch 496, Loss: 0.05709791284189949\n",
      "Epoch 497, Loss: 0.05696962428949232\n",
      "Epoch 498, Loss: 0.056841683331938925\n",
      "Epoch 499, Loss: 0.056714089027386894\n",
      "Epoch 500, Loss: 0.05658684043653838\n",
      "Epoch 501, Loss: 0.056459936622643286\n",
      "Epoch 502, Loss: 0.05633337665149203\n",
      "Epoch 503, Loss: 0.056207159591408484\n",
      "Epoch 504, Loss: 0.056081284513243304\n",
      "Epoch 505, Loss: 0.05595575049036671\n",
      "Epoch 506, Loss: 0.05583055659866145\n",
      "Epoch 507, Loss: 0.05570570191651629\n",
      "Epoch 508, Loss: 0.05558118552481878\n",
      "Epoch 509, Loss: 0.05545700650694847\n",
      "Epoch 510, Loss: 0.055333163948770296\n",
      "Epoch 511, Loss: 0.05520965693862739\n",
      "Epoch 512, Loss: 0.055086484567334615\n",
      "Epoch 513, Loss: 0.05496364592817155\n",
      "Epoch 514, Loss: 0.054841140116875936\n",
      "Epoch 515, Loss: 0.05471896623163679\n",
      "Epoch 516, Loss: 0.054597123373087794\n",
      "Epoch 517, Loss: 0.054475610644300676\n",
      "Epoch 518, Loss: 0.05435442715077826\n",
      "Epoch 519, Loss: 0.05423357200044822\n",
      "Epoch 520, Loss: 0.05411304430365625\n",
      "Epoch 521, Loss: 0.0539928431731593\n",
      "Epoch 522, Loss: 0.053872967724119314\n",
      "Epoch 523, Loss: 0.053753417074096504\n",
      "Epoch 524, Loss: 0.05363419034304294\n",
      "Epoch 525, Loss: 0.053515286653295746\n",
      "Epoch 526, Loss: 0.05339670512957077\n",
      "Epoch 527, Loss: 0.05327844489895628\n",
      "Epoch 528, Loss: 0.05316050509090618\n",
      "Epoch 529, Loss: 0.05304288483723376\n",
      "Epoch 530, Loss: 0.05292558327210524\n",
      "Epoch 531, Loss: 0.05280859953203341\n",
      "Epoch 532, Loss: 0.05269193275587105\n",
      "Epoch 533, Loss: 0.052575582084804826\n",
      "Epoch 534, Loss: 0.052459546662348755\n",
      "Epoch 535, Loss: 0.05234382563433798\n",
      "Epoch 536, Loss: 0.05222841814892232\n",
      "Epoch 537, Loss: 0.05211332335656024\n",
      "Epoch 538, Loss: 0.05199854041001224\n",
      "Epoch 539, Loss: 0.05188406846433487\n",
      "Epoch 540, Loss: 0.05176990667687432\n",
      "Epoch 541, Loss: 0.05165605420726034\n",
      "Epoch 542, Loss: 0.05154251021739991\n",
      "Epoch 543, Loss: 0.05142927387147098\n",
      "Epoch 544, Loss: 0.0513163443359167\n",
      "Epoch 545, Loss: 0.05120372077943877\n",
      "Epoch 546, Loss: 0.051091402372991625\n",
      "Epoch 547, Loss: 0.050979388289776155\n",
      "Epoch 548, Loss: 0.05086767770523378\n",
      "Epoch 549, Loss: 0.050756269797040156\n",
      "Epoch 550, Loss: 0.050645163745099295\n",
      "Epoch 551, Loss: 0.05053435873153738\n",
      "Epoch 552, Loss: 0.05042385394069688\n",
      "Epoch 553, Loss: 0.050313648559130286\n",
      "Epoch 554, Loss: 0.05020374177559438\n",
      "Epoch 555, Loss: 0.050094132781044146\n",
      "Epoch 556, Loss: 0.04998482076862682\n",
      "Epoch 557, Loss: 0.049875804933675855\n",
      "Epoch 558, Loss: 0.04976708447370517\n",
      "Epoch 559, Loss: 0.04965865858840303\n",
      "Epoch 560, Loss: 0.04955052647962632\n",
      "Epoch 561, Loss: 0.04944268735139461\n",
      "Epoch 562, Loss: 0.04933514040988415\n",
      "Epoch 563, Loss: 0.04922788486342229\n",
      "Epoch 564, Loss: 0.04912091992248144\n",
      "Epoch 565, Loss: 0.04901424479967326\n",
      "Epoch 566, Loss: 0.04890785870974284\n",
      "Epoch 567, Loss: 0.04880176086956321\n",
      "Epoch 568, Loss: 0.04869595049812921\n",
      "Epoch 569, Loss: 0.04859042681655187\n",
      "Epoch 570, Loss: 0.048485189048052664\n",
      "Epoch 571, Loss: 0.04838023641795778\n",
      "Epoch 572, Loss: 0.048275568153692536\n",
      "Epoch 573, Loss: 0.04817118348477549\n",
      "Epoch 574, Loss: 0.04806708164281288\n",
      "Epoch 575, Loss: 0.04796326186149291\n",
      "Epoch 576, Loss: 0.04785972337658031\n",
      "Epoch 577, Loss: 0.04775646542591027\n",
      "Epoch 578, Loss: 0.04765348724938328\n",
      "Epoch 579, Loss: 0.04755078808895915\n",
      "Epoch 580, Loss: 0.04744836718865195\n",
      "Epoch 581, Loss: 0.04734622379452376\n",
      "Epoch 582, Loss: 0.04724435715467972\n",
      "Epoch 583, Loss: 0.04714276651926215\n",
      "Epoch 584, Loss: 0.04704145114044512\n",
      "Epoch 585, Loss: 0.046940410272428956\n",
      "Epoch 586, Loss: 0.046839643171434714\n",
      "Epoch 587, Loss: 0.04673914909569881\n",
      "Epoch 588, Loss: 0.0466389273054674\n",
      "Epoch 589, Loss: 0.046538977062991024\n",
      "Epoch 0, Loss: 0.05025884180888669\n",
      "Epoch 1, Loss: 0.01257562781832188\n",
      "Epoch 2, Loss: 0.009941723670503735\n",
      "Epoch 3, Loss: 0.009783994354338582\n",
      "Epoch 4, Loss: 0.009750540778345706\n",
      "Epoch 0, Loss: 0.824444580500451\n",
      "Epoch 1, Loss: 0.33409538166647734\n",
      "Epoch 2, Loss: 0.2542068099340386\n",
      "Epoch 3, Loss: 0.19600113159928625\n",
      "Epoch 4, Loss: 0.15171125902503993\n",
      "Epoch 5, Loss: 0.1179560244371988\n",
      "Epoch 6, Loss: 0.09222656622585601\n",
      "Epoch 7, Loss: 0.07261451367851779\n",
      "Epoch 8, Loss: 0.057665460844539156\n",
      "Epoch 9, Loss: 0.04627078928906551\n",
      "Epoch 10, Loss: 0.03758544480990713\n",
      "Epoch 11, Loss: 0.030965277555920438\n",
      "Epoch 12, Loss: 0.025919279623429874\n",
      "Epoch 13, Loss: 0.02207317748249485\n",
      "Epoch 14, Loss: 0.019141679746683793\n",
      "Epoch 15, Loss: 0.016907322620425037\n",
      "Epoch 16, Loss: 0.015204344536017385\n",
      "Epoch 17, Loss: 0.013906394373020972\n",
      "Epoch 18, Loss: 0.01291716188750003\n",
      "Epoch 19, Loss: 0.01216323564163761\n",
      "Epoch 20, Loss: 0.011588658879528426\n",
      "Epoch 21, Loss: 0.011150779687541357\n",
      "Epoch 22, Loss: 0.010817087741479735\n",
      "Epoch 23, Loss: 0.010562803092898749\n",
      "Epoch 24, Loss: 0.01036903820689985\n",
      "Epoch 25, Loss: 0.0102213969677104\n",
      "Epoch 26, Loss: 0.010108906767749993\n",
      "Epoch 27, Loss: 0.010023204492859058\n",
      "Optimal Weights (batch_gradient_descent): [4.86038992 4.33247443]\n",
      "Number of Epochs (batch_gradient_descent): 590\n",
      "Optimal Weights (stochastic_gradient_descen): [4.51870811 4.98386542]\n",
      "Number of Epochs (stochastic_gradient_descen): 5\n",
      "Optimal Weights (mini_batch_gradient_descent): [4.54651392 4.92807301]\n",
      "Number of Epochs (mini_batch_gradient_descent): 28\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Run Batch Gradient Descent\n",
    "w_bgd, epochs_bgd = batch_gradient_descent(X_b, y_true, learning_rate, n_epochs)\n",
    "\n",
    "# Run Stochastic Gradient Descent\n",
    "w_sgd, epochs_sgd = stochastic_gradient_descent(X_b, y_true, learning_rate, n_epochs)\n",
    "\n",
    "# Run Mini-Batch Gradient Descent\n",
    "w_mbgd, epochs_mbgd = mini_batch_gradient_descent(X_b, y_true, learning_rate, n_epochs, batch_size)\n",
    "\n",
    "print(\"Optimal Weights (batch_gradient_descent):\", w_bgd)\n",
    "print(\"Number of Epochs (batch_gradient_descent):\", epochs_bgd)\n",
    "\n",
    "print(\"Optimal Weights (stochastic_gradient_descen):\", w_sgd)\n",
    "print(\"Number of Epochs (stochastic_gradient_descen):\", epochs_sgd)\n",
    "\n",
    "print(\"Optimal Weights (mini_batch_gradient_descent):\", w_mbgd)\n",
    "print(\"Number of Epochs (mini_batch_gradient_descent):\", epochs_mbgd)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f4dfcdd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 58.15885838076257\n",
      "Epoch 1, Loss: 55.295438319250835\n",
      "Epoch 2, Loss: 52.57420476674391\n",
      "Epoch 3, Loss: 49.98809404769272\n",
      "Epoch 4, Loss: 47.530393411259695\n",
      "Epoch 5, Loss: 45.194723597290334\n",
      "Epoch 6, Loss: 42.97502226841157\n",
      "Epoch 7, Loss: 40.86552826522794\n",
      "Epoch 8, Loss: 38.860766643723515\n",
      "Epoch 9, Loss: 36.95553445600968\n",
      "Epoch 10, Loss: 35.14488723748886\n",
      "Epoch 11, Loss: 33.42412616533955\n",
      "Epoch 12, Loss: 31.78878585497105\n",
      "Epoch 13, Loss: 30.234622762753496\n",
      "Epoch 14, Loss: 28.757604164903192\n",
      "Epoch 15, Loss: 27.35389768389977\n",
      "Epoch 16, Loss: 26.019861335233678\n",
      "Epoch 17, Loss: 24.75203406863374\n",
      "Epoch 18, Loss: 23.547126779209023\n",
      "Epoch 19, Loss: 22.40201376515942\n",
      "Epoch 20, Loss: 21.313724609869414\n",
      "Epoch 21, Loss: 20.279436467301515\n",
      "Epoch 22, Loss: 19.29646673065324\n",
      "Epoch 23, Loss: 18.362266065237236\n",
      "Epoch 24, Loss: 17.474411787489597\n",
      "Epoch 25, Loss: 16.63060157291077\n",
      "Epoch 26, Loss: 15.828647476597638\n",
      "Epoch 27, Loss: 15.066470250836984\n",
      "Epoch 28, Loss: 14.342093945002475\n",
      "Epoch 29, Loss: 13.653640773730109\n",
      "Epoch 30, Loss: 12.999326240043992\n",
      "Epoch 31, Loss: 12.377454500766543\n",
      "Epoch 32, Loss: 11.786413962176248\n",
      "Epoch 33, Loss: 11.224673094474303\n",
      "Epoch 34, Loss: 10.6907764541896\n",
      "Epoch 35, Loss: 10.183340904191683\n",
      "Epoch 36, Loss: 9.7010520214944\n",
      "Epoch 37, Loss: 9.2426606835208\n",
      "Epoch 38, Loss: 8.80697982396329\n",
      "Epoch 39, Loss: 8.392881349813427\n",
      "Epoch 40, Loss: 7.999293211554537\n",
      "Epoch 41, Loss: 7.625196618907855\n",
      "Epoch 42, Loss: 7.269623394901133\n",
      "Epoch 43, Loss: 6.93165346138781\n",
      "Epoch 44, Loss: 6.6104124494861916\n",
      "Epoch 45, Loss: 6.305069428732673\n",
      "Epoch 46, Loss: 6.014834749051169\n",
      "Epoch 47, Loss: 5.738957989934078\n",
      "Epoch 48, Loss: 5.476726011508449\n",
      "Epoch 49, Loss: 5.227461102425689\n",
      "Epoch 50, Loss: 4.99051921976457\n",
      "Epoch 51, Loss: 4.765288316376309\n",
      "Epoch 52, Loss: 4.551186751327581\n",
      "Epoch 53, Loss: 4.347661779313116\n",
      "Epoch 54, Loss: 4.154188115114662\n",
      "Epoch 55, Loss: 3.970266569378011\n",
      "Epoch 56, Loss: 3.7954227521649417\n",
      "Epoch 57, Loss: 3.629205840913059\n",
      "Epoch 58, Loss: 3.4711874096036857\n",
      "Epoch 59, Loss: 3.3209603160969974\n",
      "Epoch 60, Loss: 3.1781376447446257\n",
      "Epoch 61, Loss: 3.042351701533546\n",
      "Epoch 62, Loss: 2.9132530591514576\n",
      "Epoch 63, Loss: 2.790509649493575\n",
      "Epoch 64, Loss: 2.673805901253896\n",
      "Epoch 65, Loss: 2.5628419203611648\n",
      "Epoch 66, Loss: 2.4573327111309826\n",
      "Epoch 67, Loss: 2.35700743611127\n",
      "Epoch 68, Loss: 2.2616087126988087\n",
      "Epoch 69, Loss: 2.170891944700036\n",
      "Epoch 70, Loss: 2.0846246871000775\n",
      "Epoch 71, Loss: 2.0025860423902144\n",
      "Epoch 72, Loss: 1.9245660868859462\n",
      "Epoch 73, Loss: 1.8503653255457255\n",
      "Epoch 74, Loss: 1.779794173874432\n",
      "Epoch 75, Loss: 1.712672465566011\n",
      "Epoch 76, Loss: 1.6488289846065471\n",
      "Epoch 77, Loss: 1.5881010206225814\n",
      "Epoch 78, Loss: 1.530333946319827\n",
      "Epoch 79, Loss: 1.4753808159148447\n",
      "Epoch 80, Loss: 1.4231019835167211\n",
      "Epoch 81, Loss: 1.37336474046765\n",
      "Epoch 82, Loss: 1.3260429707005206\n",
      "Epoch 83, Loss: 1.2810168232184274\n",
      "Epoch 84, Loss: 1.2381724008454758\n",
      "Epoch 85, Loss: 1.1974014644405242\n",
      "Epoch 86, Loss: 1.158601151805672\n",
      "Epoch 87, Loss: 1.121673710559425\n",
      "Epoch 88, Loss: 1.086526244280803\n",
      "Epoch 89, Loss: 1.0530704712650631\n",
      "Epoch 90, Loss: 1.0212224952644984\n",
      "Epoch 91, Loss: 0.9909025876188904\n",
      "Epoch 92, Loss: 0.962034980209776\n",
      "Epoch 93, Loss: 0.9345476687007911\n",
      "Epoch 94, Loss: 0.908372225553089\n",
      "Epoch 95, Loss: 0.8834436223301922\n",
      "Epoch 96, Loss: 0.8597000608307844\n",
      "Epoch 97, Loss: 0.8370828126108634\n",
      "Epoch 98, Loss: 0.8155360664784768\n",
      "Epoch 99, Loss: 0.7950067835649504\n",
      "Epoch 100, Loss: 0.7754445595962152\n",
      "Epoch 101, Loss: 0.7568014940065277\n",
      "Epoch 102, Loss: 0.7390320655546484\n",
      "Epoch 103, Loss: 0.722093014119441\n",
      "Epoch 104, Loss: 0.7059432283678937\n",
      "Epoch 105, Loss: 0.6905436390038144\n",
      "Epoch 106, Loss: 0.6758571173199617\n",
      "Epoch 107, Loss: 0.6618483787901268\n",
      "Epoch 108, Loss: 0.6484838914507811\n",
      "Epoch 109, Loss: 0.6357317888343454\n",
      "Epoch 110, Loss: 0.6235617872279571\n",
      "Epoch 111, Loss: 0.6119451070428323\n",
      "Epoch 112, Loss: 0.6008543980900254\n",
      "Epoch 113, Loss: 0.5902636685684978\n",
      "Epoch 114, Loss: 0.5801482175810783\n",
      "Epoch 115, Loss: 0.5704845710030447\n",
      "Epoch 116, Loss: 0.561250420536767\n",
      "Epoch 117, Loss: 0.5524245657941299\n",
      "Epoch 118, Loss: 0.5439868592563126\n",
      "Epoch 119, Loss: 0.5359181539679779\n",
      "Epoch 120, Loss: 0.5282002538300239\n",
      "Epoch 121, Loss: 0.5208158663618038\n",
      "Epoch 122, Loss: 0.513748557810126\n",
      "Epoch 123, Loss: 0.5069827104884497\n",
      "Epoch 124, Loss: 0.5005034822354766\n",
      "Epoch 125, Loss: 0.49429676788784666\n",
      "Epoch 126, Loss: 0.4883491626668791\n",
      "Epoch 127, Loss: 0.482647927384267\n",
      "Epoch 128, Loss: 0.4771809553763569\n",
      "Epoch 129, Loss: 0.4719367410811419\n",
      "Epoch 130, Loss: 0.466904350176354\n",
      "Epoch 131, Loss: 0.46207339120110125\n",
      "Epoch 132, Loss: 0.45743398858734574\n",
      "Epoch 133, Loss: 0.45297675703118384\n",
      "Epoch 134, Loss: 0.4486927771373636\n",
      "Epoch 135, Loss: 0.44457357227378674\n",
      "Epoch 136, Loss: 0.44061108657588305\n",
      "Epoch 137, Loss: 0.43679766404372905\n",
      "Epoch 138, Loss: 0.43312602867762573\n",
      "Epoch 139, Loss: 0.429589265600543\n",
      "Epoch 140, Loss: 0.42618080311840273\n",
      "Epoch 141, Loss: 0.4228943956716106\n",
      "Epoch 142, Loss: 0.41972410763355583\n",
      "Epoch 143, Loss: 0.4166642979140032\n",
      "Epoch 144, Loss: 0.4137096053273925\n",
      "Epoch 145, Loss: 0.41085493468803813\n",
      "Epoch 146, Loss: 0.4080954435961236\n",
      "Epoch 147, Loss: 0.40542652988016675\n",
      "Epoch 148, Loss: 0.4028438196633446\n",
      "Epoch 149, Loss: 0.40034315602268356\n",
      "Epoch 150, Loss: 0.3979205882116624\n",
      "Epoch 151, Loss: 0.39557236141823476\n",
      "Epoch 152, Loss: 0.3932949070316749\n",
      "Epoch 153, Loss: 0.39108483339296596\n",
      "Epoch 154, Loss: 0.3889389170047083\n",
      "Epoch 155, Loss: 0.38685409417772043\n",
      "Epoch 156, Loss: 0.3848274530926355\n",
      "Epoch 157, Loss: 0.38285622625587795\n",
      "Epoch 158, Loss: 0.38093778333042644\n",
      "Epoch 159, Loss: 0.3790696243227434\n",
      "Epoch 160, Loss: 0.37724937310817824\n",
      "Epoch 161, Loss: 0.375474771278027\n",
      "Epoch 162, Loss: 0.37374367229226946\n",
      "Epoch 163, Loss: 0.3720540359227972\n",
      "Epoch 164, Loss: 0.3704039229727013\n",
      "Epoch 165, Loss: 0.36879149025790514\n",
      "Epoch 166, Loss: 0.3672149858381072\n",
      "Epoch 167, Loss: 0.3656727444846508\n",
      "Epoch 168, Loss: 0.36416318337354886\n",
      "Epoch 169, Loss: 0.3626847979924767\n",
      "Epoch 170, Loss: 0.3612361582511053\n",
      "Epoch 171, Loss: 0.35981590478467135\n",
      "Epoch 172, Loss: 0.3584227454411846\n",
      "Epoch 173, Loss: 0.35705545194314914\n",
      "Epoch 174, Loss: 0.35571285671512887\n",
      "Epoch 175, Loss: 0.35439384986891836\n",
      "Epoch 176, Loss: 0.35309737633848864\n",
      "Epoch 177, Loss: 0.35182243315726686\n",
      "Epoch 178, Loss: 0.3505680668706799\n",
      "Epoch 179, Loss: 0.3493333710772402\n",
      "Epoch 180, Loss: 0.34811748409178994\n",
      "Epoch 181, Loss: 0.34691958672483225\n",
      "Epoch 182, Loss: 0.3457389001721842\n",
      "Epoch 183, Loss: 0.34457468400947056\n",
      "Epoch 184, Loss: 0.3434262342862479\n",
      "Epoch 185, Loss: 0.3422928817148124\n",
      "Epoch 186, Loss: 0.34117398994898485\n",
      "Epoch 187, Loss: 0.3400689539484042\n",
      "Epoch 188, Loss: 0.3389771984240808\n",
      "Epoch 189, Loss: 0.3378981763611733\n",
      "Epoch 190, Loss: 0.3368313676151513\n",
      "Epoch 191, Loss: 0.33577627757769984\n",
      "Epoch 192, Loss: 0.33473243590889845\n",
      "Epoch 193, Loss: 0.33369939533238524\n",
      "Epoch 194, Loss: 0.3326767304903737\n",
      "Epoch 195, Loss: 0.33166403685555157\n",
      "Epoch 196, Loss: 0.33066092969703426\n",
      "Epoch 197, Loss: 0.32966704309768735\n",
      "Epoch 198, Loss: 0.32868202902026694\n",
      "Epoch 199, Loss: 0.3277055564199526\n",
      "Epoch 200, Loss: 0.3267373104009666\n",
      "Epoch 201, Loss: 0.3257769914150912\n",
      "Epoch 202, Loss: 0.32482431450000154\n",
      "Epoch 203, Loss: 0.32387900855543617\n",
      "Epoch 204, Loss: 0.3229408156553246\n",
      "Epoch 205, Loss: 0.3220094903940883\n",
      "Epoch 206, Loss: 0.3210847992654127\n",
      "Epoch 207, Loss: 0.3201665200718825\n",
      "Epoch 208, Loss: 0.3192544413639429\n",
      "Epoch 209, Loss: 0.3183483619067308\n",
      "Epoch 210, Loss: 0.31744809017339387\n",
      "Epoch 211, Loss: 0.3165534438635767\n",
      "Epoch 212, Loss: 0.3156642494458291\n",
      "Epoch 213, Loss: 0.314780341722744\n",
      "Epoch 214, Loss: 0.31390156341769754\n",
      "Epoch 215, Loss: 0.31302776478211924\n",
      "Epoch 216, Loss: 0.31215880322226824\n",
      "Epoch 217, Loss: 0.3112945429445524\n",
      "Epoch 218, Loss: 0.310434854618464\n",
      "Epoch 219, Loss: 0.30957961505625897\n",
      "Epoch 220, Loss: 0.3087287069085484\n",
      "Epoch 221, Loss: 0.30788201837501067\n",
      "Epoch 222, Loss: 0.30703944292947305\n",
      "Epoch 223, Loss: 0.3062008790586499\n",
      "Epoch 224, Loss: 0.30536623001385815\n",
      "Epoch 225, Loss: 0.3045354035750652\n",
      "Epoch 226, Loss: 0.3037083118266571\n",
      "Epoch 227, Loss: 0.3028848709443456\n",
      "Epoch 228, Loss: 0.30206500099265726\n",
      "Epoch 229, Loss: 0.30124862573248445\n",
      "Epoch 230, Loss: 0.3004356724381929\n",
      "Epoch 231, Loss: 0.2996260717238135\n",
      "Epoch 232, Loss: 0.29881975737786903\n",
      "Epoch 233, Loss: 0.298016666206402\n",
      "Epoch 234, Loss: 0.2972167378838001\n",
      "Epoch 235, Loss: 0.2964199148110321\n",
      "Epoch 236, Loss: 0.29562614198092174\n",
      "Epoch 237, Loss: 0.2948353668501152\n",
      "Epoch 238, Loss: 0.29404753921740623\n",
      "Epoch 239, Loss: 0.2932626111081046\n",
      "Epoch 240, Loss: 0.2924805366641467\n",
      "Epoch 241, Loss: 0.29170127203966406\n",
      "Epoch 242, Loss: 0.29092477530173744\n",
      "Epoch 243, Loss: 0.2901510063360803\n",
      "Epoch 244, Loss: 0.28937992675740554\n",
      "Epoch 245, Loss: 0.28861149982424306\n",
      "Epoch 246, Loss: 0.2878456903579879\n",
      "Epoch 247, Loss: 0.28708246466596765\n",
      "Epoch 248, Loss: 0.2863217904683303\n",
      "Epoch 249, Loss: 0.28556363682856195\n",
      "Epoch 250, Loss: 0.2848079740874551\n",
      "Epoch 251, Loss: 0.28405477380035504\n",
      "Epoch 252, Loss: 0.28330400867752215\n",
      "Epoch 253, Loss: 0.28255565252745485\n",
      "Epoch 254, Loss: 0.2818096802030272\n",
      "Epoch 255, Loss: 0.28106606755029917\n",
      "Epoch 256, Loss: 0.28032479135986943\n",
      "Epoch 257, Loss: 0.27958582932064213\n",
      "Epoch 258, Loss: 0.27884915997588927\n",
      "Epoch 259, Loss: 0.27811476268149393\n",
      "Epoch 260, Loss: 0.2773826175662659\n",
      "Epoch 261, Loss: 0.2766527054942271\n",
      "Epoch 262, Loss: 0.27592500802876874\n",
      "Epoch 263, Loss: 0.27519950739858773\n",
      "Epoch 264, Loss: 0.2744761864653126\n",
      "Epoch 265, Loss: 0.2737550286927372\n",
      "Epoch 266, Loss: 0.2730360181175799\n",
      "Epoch 267, Loss: 0.2723191393216943\n",
      "Epoch 268, Loss: 0.2716043774056585\n",
      "Epoch 269, Loss: 0.27089171796367484\n",
      "Epoch 270, Loss: 0.27018114705971424\n",
      "Epoch 271, Loss: 0.26947265120484437\n",
      "Epoch 272, Loss: 0.2687662173356827\n",
      "Epoch 273, Loss: 0.268061832793917\n",
      "Epoch 274, Loss: 0.26735948530684317\n",
      "Epoch 275, Loss: 0.26665916296886644\n",
      "Epoch 276, Loss: 0.2659608542239211\n",
      "Epoch 277, Loss: 0.2652645478487608\n",
      "Epoch 278, Loss: 0.2645702329370783\n",
      "Epoch 279, Loss: 0.26387789888441215\n",
      "Epoch 280, Loss: 0.26318753537379985\n",
      "Epoch 281, Loss: 0.2624991323621446\n",
      "Epoch 282, Loss: 0.2618126800672556\n",
      "Epoch 283, Loss: 0.2611281689555315\n",
      "Epoch 284, Loss: 0.2604455897302531\n",
      "Epoch 285, Loss: 0.25976493332045725\n",
      "Epoch 286, Loss: 0.25908619087036017\n",
      "Epoch 287, Loss: 0.2584093537293055\n",
      "Epoch 288, Loss: 0.2577344134422102\n",
      "Epoch 289, Loss: 0.2570613617404822\n",
      "Epoch 290, Loss: 0.2563901905333892\n",
      "Epoch 291, Loss: 0.255720891899853\n",
      "Epoch 292, Loss: 0.2550534580806506\n",
      "Epoch 293, Loss: 0.2543878814710009\n",
      "Epoch 294, Loss: 0.2537241546135181\n",
      "Epoch 295, Loss: 0.2530622701915134\n",
      "Epoch 296, Loss: 0.25240222102262694\n",
      "Epoch 297, Loss: 0.2517440000527767\n",
      "Epoch 298, Loss: 0.2510876003504037\n",
      "Epoch 299, Loss: 0.25043301510100247\n",
      "Epoch 300, Loss: 0.24978023760192283\n",
      "Epoch 301, Loss: 0.24912926125742607\n",
      "Epoch 302, Loss: 0.2484800795739863\n",
      "Epoch 303, Loss: 0.24783268615582368\n",
      "Epoch 304, Loss: 0.24718707470065765\n",
      "Epoch 305, Loss: 0.24654323899566896\n",
      "Epoch 306, Loss: 0.24590117291366162\n",
      "Epoch 307, Loss: 0.2452608704094129\n",
      "Epoch 308, Loss: 0.2446223255162042\n",
      "Epoch 309, Loss: 0.2439855323425214\n",
      "Epoch 310, Loss: 0.24335048506891857\n",
      "Epoch 311, Loss: 0.24271717794503492\n",
      "Epoch 312, Loss: 0.24208560528675893\n",
      "Epoch 313, Loss: 0.24145576147353193\n",
      "Epoch 314, Loss: 0.24082764094578316\n",
      "Epoch 315, Loss: 0.24020123820249153\n",
      "Epoch 316, Loss: 0.23957654779886667\n",
      "Epoch 317, Loss: 0.23895356434414322\n",
      "Epoch 318, Loss: 0.23833228249948343\n",
      "Epoch 319, Loss: 0.23771269697598257\n",
      "Epoch 320, Loss: 0.23709480253277143\n",
      "Epoch 321, Loss: 0.2364785939752116\n",
      "Epoch 322, Loss: 0.23586406615317887\n",
      "Epoch 323, Loss: 0.2352512139594307\n",
      "Epoch 324, Loss: 0.23464003232805247\n",
      "Epoch 325, Loss: 0.23403051623298024\n",
      "Epoch 326, Loss: 0.23342266068659456\n",
      "Epoch 327, Loss: 0.23281646073838305\n",
      "Epoch 328, Loss: 0.23221191147366774\n",
      "Epoch 329, Loss: 0.231609008012394\n",
      "Epoch 330, Loss: 0.23100774550797826\n",
      "Epoch 331, Loss: 0.23040811914621134\n",
      "Epoch 332, Loss: 0.22981012414421503\n",
      "Epoch 333, Loss: 0.22921375574944794\n",
      "Epoch 334, Loss: 0.2286190092387607\n",
      "Epoch 335, Loss: 0.22802587991749573\n",
      "Epoch 336, Loss: 0.22743436311862994\n",
      "Epoch 337, Loss: 0.22684445420195937\n",
      "Epoch 338, Loss: 0.226256148553322\n",
      "Epoch 339, Loss: 0.22566944158385832\n",
      "Epoch 340, Loss: 0.22508432872930673\n",
      "Epoch 341, Loss: 0.22450080544933218\n",
      "Epoch 342, Loss: 0.22391886722688784\n",
      "Epoch 343, Loss: 0.22333850956760537\n",
      "Epoch 344, Loss: 0.2227597279992154\n",
      "Epoch 345, Loss: 0.2221825180709944\n",
      "Epoch 346, Loss: 0.2216068753532383\n",
      "Epoch 347, Loss: 0.22103279543675977\n",
      "Epoch 348, Loss: 0.22046027393241033\n",
      "Epoch 349, Loss: 0.21988930647062357\n",
      "Epoch 350, Loss: 0.2193198887009801\n",
      "Epoch 351, Loss: 0.21875201629179253\n",
      "Epoch 352, Loss: 0.2181856849297102\n",
      "Epoch 353, Loss: 0.217620890319341\n",
      "Epoch 354, Loss: 0.21705762818289165\n",
      "Epoch 355, Loss: 0.21649589425982332\n",
      "Epoch 356, Loss: 0.21593568430652402\n",
      "Epoch 357, Loss: 0.2153769940959951\n",
      "Epoch 358, Loss: 0.21481981941755185\n",
      "Epoch 359, Loss: 0.21426415607653843\n",
      "Epoch 360, Loss: 0.21370999989405431\n",
      "Epoch 361, Loss: 0.21315734670669376\n",
      "Epoch 362, Loss: 0.21260619236629646\n",
      "Epoch 363, Loss: 0.21205653273970929\n",
      "Epoch 364, Loss: 0.21150836370855866\n",
      "Epoch 365, Loss: 0.2109616811690322\n",
      "Epoch 366, Loss: 0.21041648103167057\n",
      "Epoch 367, Loss: 0.20987275922116783\n",
      "Epoch 368, Loss: 0.20933051167618022\n",
      "Epoch 369, Loss: 0.2087897343491435\n",
      "Epoch 370, Loss: 0.20825042320609766\n",
      "Epoch 371, Loss: 0.20771257422651895\n",
      "Epoch 372, Loss: 0.20717618340315913\n",
      "Epoch 373, Loss: 0.20664124674189105\n",
      "Epoch 374, Loss: 0.2061077602615605\n",
      "Epoch 375, Loss: 0.2055757199938444\n",
      "Epoch 376, Loss: 0.20504512198311448\n",
      "Epoch 377, Loss: 0.20451596228630628\n",
      "Epoch 378, Loss: 0.20398823697279336\n",
      "Epoch 379, Loss: 0.2034619421242666\n",
      "Epoch 380, Loss: 0.2029370738346177\n",
      "Epoch 381, Loss: 0.20241362820982783\n",
      "Epoch 382, Loss: 0.20189160136785964\n",
      "Epoch 383, Loss: 0.20137098943855405\n",
      "Epoch 384, Loss: 0.20085178856353023\n",
      "Epoch 385, Loss: 0.2003339948960895\n",
      "Epoch 386, Loss: 0.1998176046011231\n",
      "Epoch 387, Loss: 0.19930261385502218\n",
      "Epoch 388, Loss: 0.19878901884559205\n",
      "Epoch 389, Loss: 0.1982768157719686\n",
      "Epoch 390, Loss: 0.19776600084453777\n",
      "Epoch 391, Loss: 0.19725657028485824\n",
      "Epoch 392, Loss: 0.19674852032558554\n",
      "Epoch 393, Loss: 0.19624184721039994\n",
      "Epoch 394, Loss: 0.19573654719393568\n",
      "Epoch 395, Loss: 0.19523261654171264\n",
      "Epoch 396, Loss: 0.19473005153007011\n",
      "Epoch 397, Loss: 0.1942288484461032\n",
      "Epoch 398, Loss: 0.1937290035875999\n",
      "Epoch 399, Loss: 0.19323051326298116\n",
      "Epoch 400, Loss: 0.19273337379124197\n",
      "Epoch 401, Loss: 0.1922375815018943\n",
      "Epoch 402, Loss: 0.19174313273491136\n",
      "Epoch 403, Loss: 0.19125002384067438\n",
      "Epoch 404, Loss: 0.19075825117991907\n",
      "Epoch 405, Loss: 0.19026781112368507\n",
      "Epoch 406, Loss: 0.18977870005326572\n",
      "Epoch 407, Loss: 0.18929091436015955\n",
      "Epoch 408, Loss: 0.18880445044602231\n",
      "Epoch 409, Loss: 0.1883193047226212\n",
      "Epoch 410, Loss: 0.18783547361178893\n",
      "Epoch 411, Loss: 0.1873529535453796\n",
      "Epoch 412, Loss: 0.18687174096522535\n",
      "Epoch 413, Loss: 0.18639183232309403\n",
      "Epoch 414, Loss: 0.18591322408064753\n",
      "Epoch 415, Loss: 0.1854359127094007\n",
      "Epoch 416, Loss: 0.18495989469068233\n",
      "Epoch 417, Loss: 0.18448516651559474\n",
      "Epoch 418, Loss: 0.1840117246849765\n",
      "Epoch 419, Loss: 0.18353956570936408\n",
      "Epoch 420, Loss: 0.18306868610895485\n",
      "Epoch 421, Loss: 0.18259908241357073\n",
      "Epoch 422, Loss: 0.1821307511626224\n",
      "Epoch 423, Loss: 0.18166368890507417\n",
      "Epoch 424, Loss: 0.18119789219940893\n",
      "Epoch 425, Loss: 0.18073335761359438\n",
      "Epoch 426, Loss: 0.18027008172504908\n",
      "Epoch 427, Loss: 0.1798080611206094\n",
      "Epoch 428, Loss: 0.17934729239649716\n",
      "Epoch 429, Loss: 0.17888777215828663\n",
      "Epoch 430, Loss: 0.1784294970208734\n",
      "Epoch 431, Loss: 0.17797246360844293\n",
      "Epoch 432, Loss: 0.17751666855443887\n",
      "Epoch 433, Loss: 0.17706210850153317\n",
      "Epoch 434, Loss: 0.1766087801015954\n",
      "Epoch 435, Loss: 0.17615668001566276\n",
      "Epoch 436, Loss: 0.17570580491391086\n",
      "Epoch 437, Loss: 0.17525615147562382\n",
      "Epoch 438, Loss: 0.17480771638916587\n",
      "Epoch 439, Loss: 0.17436049635195228\n",
      "Epoch 440, Loss: 0.1739144880704211\n",
      "Epoch 441, Loss: 0.17346968826000495\n",
      "Epoch 442, Loss: 0.17302609364510296\n",
      "Epoch 443, Loss: 0.1725837009590537\n",
      "Epoch 444, Loss: 0.17214250694410713\n",
      "Epoch 445, Loss: 0.17170250835139766\n",
      "Epoch 446, Loss: 0.17126370194091753\n",
      "Epoch 447, Loss: 0.1708260844814897\n",
      "Epoch 448, Loss: 0.17038965275074128\n",
      "Epoch 449, Loss: 0.16995440353507762\n",
      "Epoch 450, Loss: 0.16952033362965588\n",
      "Epoch 451, Loss: 0.16908743983835905\n",
      "Epoch 452, Loss: 0.16865571897377038\n",
      "Epoch 453, Loss: 0.16822516785714772\n",
      "Epoch 454, Loss: 0.16779578331839826\n",
      "Epoch 455, Loss: 0.167367562196053\n",
      "Epoch 456, Loss: 0.16694050133724173\n",
      "Epoch 457, Loss: 0.16651459759766835\n",
      "Epoch 458, Loss: 0.1660898478415857\n",
      "Epoch 459, Loss: 0.1656662489417713\n",
      "Epoch 460, Loss: 0.16524379777950254\n",
      "Epoch 461, Loss: 0.16482249124453244\n",
      "Epoch 462, Loss: 0.16440232623506545\n",
      "Epoch 463, Loss: 0.1639832996577334\n",
      "Epoch 464, Loss: 0.16356540842757114\n",
      "Epoch 465, Loss: 0.16314864946799337\n",
      "Epoch 466, Loss: 0.16273301971077012\n",
      "Epoch 467, Loss: 0.1623185160960037\n",
      "Epoch 468, Loss: 0.16190513557210506\n",
      "Epoch 469, Loss: 0.16149287509577015\n",
      "Epoch 470, Loss: 0.16108173163195705\n",
      "Epoch 471, Loss: 0.16067170215386228\n",
      "Epoch 472, Loss: 0.16026278364289795\n",
      "Epoch 473, Loss: 0.15985497308866906\n",
      "Epoch 474, Loss: 0.15944826748895016\n",
      "Epoch 475, Loss: 0.1590426638496629\n",
      "Epoch 476, Loss: 0.15863815918485302\n",
      "Epoch 477, Loss: 0.158234750516668\n",
      "Epoch 478, Loss: 0.1578324348753344\n",
      "Epoch 479, Loss: 0.15743120929913557\n",
      "Epoch 480, Loss: 0.1570310708343892\n",
      "Epoch 481, Loss: 0.15663201653542513\n",
      "Epoch 482, Loss: 0.15623404346456318\n",
      "Epoch 483, Loss: 0.15583714869209092\n",
      "Epoch 484, Loss: 0.15544132929624196\n",
      "Epoch 485, Loss: 0.15504658236317378\n",
      "Epoch 486, Loss: 0.15465290498694606\n",
      "Epoch 487, Loss: 0.15426029426949855\n",
      "Epoch 488, Loss: 0.15386874732062997\n",
      "Epoch 489, Loss: 0.15347826125797592\n",
      "Epoch 490, Loss: 0.15308883320698766\n",
      "Epoch 491, Loss: 0.15270046030091028\n",
      "Epoch 492, Loss: 0.15231313968076157\n",
      "Epoch 493, Loss: 0.1519268684953107\n",
      "Epoch 494, Loss: 0.15154164390105695\n",
      "Epoch 495, Loss: 0.15115746306220842\n",
      "Epoch 496, Loss: 0.15077432315066094\n",
      "Epoch 497, Loss: 0.15039222134597713\n",
      "Epoch 498, Loss: 0.15001115483536562\n",
      "Epoch 499, Loss: 0.1496311208136594\n",
      "Epoch 500, Loss: 0.14925211648329575\n",
      "Epoch 501, Loss: 0.14887413905429536\n",
      "Epoch 502, Loss: 0.14849718574424103\n",
      "Epoch 503, Loss: 0.14812125377825777\n",
      "Epoch 504, Loss: 0.1477463403889917\n",
      "Epoch 505, Loss: 0.1473724428165898\n",
      "Epoch 506, Loss: 0.14699955830867942\n",
      "Epoch 507, Loss: 0.14662768412034763\n",
      "Epoch 508, Loss: 0.14625681751412134\n",
      "Epoch 509, Loss: 0.1458869557599463\n",
      "Epoch 510, Loss: 0.14551809613516808\n",
      "Epoch 511, Loss: 0.14515023592451062\n",
      "Epoch 512, Loss: 0.14478337242005684\n",
      "Epoch 513, Loss: 0.14441750292122862\n",
      "Epoch 514, Loss: 0.1440526247347667\n",
      "Epoch 515, Loss: 0.14368873517471045\n",
      "Epoch 516, Loss: 0.1433258315623787\n",
      "Epoch 517, Loss: 0.14296391122634922\n",
      "Epoch 518, Loss: 0.14260297150243953\n",
      "Epoch 519, Loss: 0.14224300973368684\n",
      "Epoch 520, Loss: 0.1418840232703289\n",
      "Epoch 521, Loss: 0.14152600946978358\n",
      "Epoch 522, Loss: 0.14116896569663032\n",
      "Epoch 523, Loss: 0.1408128893225902\n",
      "Epoch 524, Loss: 0.14045777772650628\n",
      "Epoch 525, Loss: 0.14010362829432477\n",
      "Epoch 526, Loss: 0.13975043841907553\n",
      "Epoch 527, Loss: 0.13939820550085263\n",
      "Epoch 528, Loss: 0.13904692694679557\n",
      "Epoch 529, Loss: 0.13869660017106972\n",
      "Epoch 530, Loss: 0.13834722259484755\n",
      "Epoch 531, Loss: 0.13799879164628934\n",
      "Epoch 532, Loss: 0.13765130476052467\n",
      "Epoch 533, Loss: 0.13730475937963307\n",
      "Epoch 534, Loss: 0.13695915295262517\n",
      "Epoch 535, Loss: 0.13661448293542425\n",
      "Epoch 536, Loss: 0.13627074679084691\n",
      "Epoch 537, Loss: 0.13592794198858502\n",
      "Epoch 538, Loss: 0.13558606600518658\n",
      "Epoch 539, Loss: 0.13524511632403735\n",
      "Epoch 540, Loss: 0.13490509043534213\n",
      "Epoch 541, Loss: 0.13456598583610652\n",
      "Epoch 542, Loss: 0.1342278000301182\n",
      "Epoch 543, Loss: 0.13389053052792874\n",
      "Epoch 544, Loss: 0.133554174846835\n",
      "Epoch 545, Loss: 0.1332187305108611\n",
      "Epoch 546, Loss: 0.13288419505074023\n",
      "Epoch 547, Loss: 0.132550566003896\n",
      "Epoch 548, Loss: 0.1322178409144248\n",
      "Epoch 549, Loss: 0.13188601733307737\n",
      "Epoch 550, Loss: 0.13155509281724118\n",
      "Epoch 551, Loss: 0.13122506493092165\n",
      "Epoch 552, Loss: 0.13089593124472515\n",
      "Epoch 553, Loss: 0.13056768933584031\n",
      "Epoch 554, Loss: 0.1302403367880209\n",
      "Epoch 555, Loss: 0.1299138711915672\n",
      "Epoch 556, Loss: 0.1295882901433089\n",
      "Epoch 557, Loss: 0.12926359124658732\n",
      "Epoch 558, Loss: 0.12893977211123753\n",
      "Epoch 559, Loss: 0.12861683035357072\n",
      "Epoch 560, Loss: 0.12829476359635705\n",
      "Epoch 561, Loss: 0.12797356946880767\n",
      "Epoch 562, Loss: 0.1276532456065574\n",
      "Epoch 563, Loss: 0.12733378965164752\n",
      "Epoch 564, Loss: 0.12701519925250818\n",
      "Epoch 565, Loss: 0.12669747206394127\n",
      "Epoch 566, Loss: 0.12638060574710286\n",
      "Epoch 567, Loss: 0.12606459796948624\n",
      "Epoch 568, Loss: 0.12574944640490476\n",
      "Epoch 569, Loss: 0.12543514873347447\n",
      "Epoch 570, Loss: 0.12512170264159725\n",
      "Epoch 571, Loss: 0.12480910582194359\n",
      "Epoch 572, Loss: 0.12449735597343585\n",
      "Epoch 573, Loss: 0.12418645080123102\n",
      "Epoch 574, Loss: 0.12387638801670414\n",
      "Epoch 575, Loss: 0.12356716533743115\n",
      "Epoch 576, Loss: 0.12325878048717229\n",
      "Epoch 577, Loss: 0.12295123119585522\n",
      "Epoch 578, Loss: 0.12264451519955841\n",
      "Epoch 579, Loss: 0.12233863024049435\n",
      "Epoch 580, Loss: 0.122033574066993\n",
      "Epoch 581, Loss: 0.12172934443348529\n",
      "Epoch 582, Loss: 0.12142593910048646\n",
      "Epoch 583, Loss: 0.12112335583457955\n",
      "Epoch 584, Loss: 0.12082159240839908\n",
      "Epoch 585, Loss: 0.12052064660061457\n",
      "Epoch 586, Loss: 0.12022051619591423\n",
      "Epoch 587, Loss: 0.1199211989849886\n",
      "Epoch 588, Loss: 0.11962269276451426\n",
      "Epoch 589, Loss: 0.1193249953371378\n",
      "Epoch 590, Loss: 0.11902810451145941\n",
      "Epoch 591, Loss: 0.11873201810201689\n",
      "Epoch 592, Loss: 0.11843673392926951\n",
      "Epoch 593, Loss: 0.11814224981958191\n",
      "Epoch 594, Loss: 0.11784856360520814\n",
      "Epoch 595, Loss: 0.11755567312427581\n",
      "Epoch 596, Loss: 0.11726357622077009\n",
      "Epoch 597, Loss: 0.11697227074451769\n",
      "Epoch 598, Loss: 0.11668175455117137\n",
      "Epoch 599, Loss: 0.11639202550219369\n",
      "Epoch 600, Loss: 0.11610308146484175\n",
      "Epoch 601, Loss: 0.11581492031215117\n",
      "Epoch 602, Loss: 0.11552753992292063\n",
      "Epoch 603, Loss: 0.11524093818169598\n",
      "Epoch 604, Loss: 0.1149551129787551\n",
      "Epoch 605, Loss: 0.11467006221009171\n",
      "Epoch 606, Loss: 0.11438578377740077\n",
      "Epoch 607, Loss: 0.11410227558806224\n",
      "Epoch 608, Loss: 0.11381953555512604\n",
      "Epoch 609, Loss: 0.11353756159729655\n",
      "Epoch 610, Loss: 0.11325635163891758\n",
      "Epoch 611, Loss: 0.11297590360995667\n",
      "Epoch 612, Loss: 0.11269621544599019\n",
      "Epoch 613, Loss: 0.11241728508818795\n",
      "Epoch 614, Loss: 0.112139110483298\n",
      "Epoch 615, Loss: 0.11186168958363199\n",
      "Epoch 616, Loss: 0.11158502034704929\n",
      "Epoch 617, Loss: 0.11130910073694261\n",
      "Epoch 618, Loss: 0.11103392872222273\n",
      "Epoch 619, Loss: 0.11075950227730369\n",
      "Epoch 620, Loss: 0.11048581938208771\n",
      "Epoch 621, Loss: 0.1102128780219505\n",
      "Epoch 622, Loss: 0.10994067618772614\n",
      "Epoch 623, Loss: 0.10966921187569278\n",
      "Epoch 624, Loss: 0.10939848308755738\n",
      "Epoch 625, Loss: 0.10912848783044125\n",
      "Epoch 626, Loss: 0.10885922411686548\n",
      "Epoch 627, Loss: 0.1085906899647359\n",
      "Epoch 628, Loss: 0.1083228833973291\n",
      "Epoch 629, Loss: 0.10805580244327737\n",
      "Epoch 630, Loss: 0.10778944513655433\n",
      "Epoch 631, Loss: 0.10752380951646054\n",
      "Epoch 632, Loss: 0.10725889362760901\n",
      "Epoch 633, Loss: 0.10699469551991089\n",
      "Epoch 634, Loss: 0.1067312132485608\n",
      "Epoch 635, Loss: 0.1064684448740231\n",
      "Epoch 636, Loss: 0.10620638846201698\n",
      "Epoch 637, Loss: 0.10594504208350267\n",
      "Epoch 638, Loss: 0.10568440381466693\n",
      "Epoch 639, Loss: 0.10542447173690912\n",
      "Epoch 640, Loss: 0.10516524393682704\n",
      "Epoch 641, Loss: 0.10490671850620274\n",
      "Epoch 642, Loss: 0.10464889354198843\n",
      "Epoch 643, Loss: 0.10439176714629278\n",
      "Epoch 644, Loss: 0.10413533742636658\n",
      "Epoch 645, Loss: 0.10387960249458901\n",
      "Epoch 646, Loss: 0.10362456046845372\n",
      "Epoch 647, Loss: 0.10337020947055486\n",
      "Epoch 648, Loss: 0.10311654762857354\n",
      "Epoch 649, Loss: 0.10286357307526368\n",
      "Epoch 650, Loss: 0.10261128394843845\n",
      "Epoch 651, Loss: 0.10235967839095676\n",
      "Epoch 652, Loss: 0.10210875455070914\n",
      "Epoch 653, Loss: 0.10185851058060459\n",
      "Epoch 654, Loss: 0.10160894463855638\n",
      "Epoch 655, Loss: 0.10136005488746926\n",
      "Epoch 656, Loss: 0.10111183949522538\n",
      "Epoch 657, Loss: 0.10086429663467089\n",
      "Epoch 658, Loss: 0.10061742448360265\n",
      "Epoch 659, Loss: 0.1003712212247546\n",
      "Epoch 660, Loss: 0.10012568504578462\n",
      "Epoch 661, Loss: 0.09988081413926103\n",
      "Epoch 662, Loss: 0.09963660670264934\n",
      "Epoch 663, Loss: 0.09939306093829899\n",
      "Epoch 664, Loss: 0.09915017505343003\n",
      "Epoch 665, Loss: 0.09890794726012006\n",
      "Epoch 666, Loss: 0.09866637577529097\n",
      "Epoch 667, Loss: 0.0984254588206959\n",
      "Epoch 668, Loss: 0.09818519462290595\n",
      "Epoch 669, Loss: 0.09794558141329741\n",
      "Epoch 670, Loss: 0.09770661742803866\n",
      "Epoch 671, Loss: 0.0974683009080768\n",
      "Epoch 672, Loss: 0.09723063009912541\n",
      "Epoch 673, Loss: 0.09699360325165099\n",
      "Epoch 674, Loss: 0.09675721862086055\n",
      "Epoch 675, Loss: 0.09652147446668839\n",
      "Epoch 676, Loss: 0.09628636905378354\n",
      "Epoch 677, Loss: 0.09605190065149688\n",
      "Epoch 678, Loss: 0.09581806753386848\n",
      "Epoch 679, Loss: 0.09558486797961481\n",
      "Epoch 680, Loss: 0.09535230027211608\n",
      "Epoch 681, Loss: 0.09512036269940365\n",
      "Epoch 682, Loss: 0.09488905355414747\n",
      "Epoch 683, Loss: 0.09465837113364332\n",
      "Epoch 684, Loss: 0.09442831373980053\n",
      "Epoch 685, Loss: 0.09419887967912925\n",
      "Epoch 686, Loss: 0.09397006726272807\n",
      "Epoch 687, Loss: 0.0937418748062717\n",
      "Epoch 688, Loss: 0.09351430062999858\n",
      "Epoch 689, Loss: 0.09328734305869799\n",
      "Epoch 690, Loss: 0.09306100042169871\n",
      "Epoch 691, Loss: 0.09283527105285563\n",
      "Epoch 692, Loss: 0.09261015329053832\n",
      "Epoch 693, Loss: 0.09238564547761852\n",
      "Epoch 694, Loss: 0.0921617459614576\n",
      "Epoch 695, Loss: 0.09193845309389494\n",
      "Epoch 696, Loss: 0.09171576523123565\n",
      "Epoch 697, Loss: 0.09149368073423798\n",
      "Epoch 698, Loss: 0.09127219796810206\n",
      "Epoch 699, Loss: 0.09105131530245737\n",
      "Epoch 700, Loss: 0.09083103111135062\n",
      "Epoch 701, Loss: 0.09061134377323418\n",
      "Epoch 702, Loss: 0.09039225167095395\n",
      "Epoch 703, Loss: 0.09017375319173743\n",
      "Epoch 704, Loss: 0.08995584672718183\n",
      "Epoch 705, Loss: 0.08973853067324228\n",
      "Epoch 706, Loss: 0.08952180343022008\n",
      "Epoch 707, Loss: 0.08930566340275081\n",
      "Epoch 708, Loss: 0.0890901089997927\n",
      "Epoch 709, Loss: 0.08887513863461467\n",
      "Epoch 710, Loss: 0.08866075072478513\n",
      "Epoch 711, Loss: 0.08844694369215989\n",
      "Epoch 712, Loss: 0.08823371596287063\n",
      "Epoch 713, Loss: 0.08802106596731334\n",
      "Epoch 714, Loss: 0.087808992140137\n",
      "Epoch 715, Loss: 0.08759749292023185\n",
      "Epoch 716, Loss: 0.08738656675071772\n",
      "Epoch 717, Loss: 0.08717621207893282\n",
      "Epoch 718, Loss: 0.08696642735642231\n",
      "Epoch 719, Loss: 0.08675721103892683\n",
      "Epoch 720, Loss: 0.08654856158637107\n",
      "Epoch 721, Loss: 0.0863404774628526\n",
      "Epoch 722, Loss: 0.08613295713663044\n",
      "Epoch 723, Loss: 0.08592599908011374\n",
      "Epoch 724, Loss: 0.0857196017698506\n",
      "Epoch 725, Loss: 0.08551376368651704\n",
      "Epoch 726, Loss: 0.08530848331490551\n",
      "Epoch 727, Loss: 0.08510375914391398\n",
      "Epoch 728, Loss: 0.08489958966653437\n",
      "Epoch 729, Loss: 0.08469597337984215\n",
      "Epoch 730, Loss: 0.08449290878498486\n",
      "Epoch 731, Loss: 0.08429039438717095\n",
      "Epoch 732, Loss: 0.08408842869565916\n",
      "Epoch 733, Loss: 0.08388701022374725\n",
      "Epoch 734, Loss: 0.08368613748876123\n",
      "Epoch 735, Loss: 0.08348580901204423\n",
      "Epoch 736, Loss: 0.08328602331894577\n",
      "Epoch 737, Loss: 0.08308677893881108\n",
      "Epoch 738, Loss: 0.08288807440496981\n",
      "Epoch 739, Loss: 0.0826899082547258\n",
      "Epoch 740, Loss: 0.08249227902934572\n",
      "Epoch 741, Loss: 0.08229518527404887\n",
      "Epoch 742, Loss: 0.0820986255379961\n",
      "Epoch 743, Loss: 0.08190259837427927\n",
      "Epoch 744, Loss: 0.08170710233991064\n",
      "Epoch 745, Loss: 0.08151213599581221\n",
      "Epoch 746, Loss: 0.08131769790680508\n",
      "Epoch 747, Loss: 0.08112378664159886\n",
      "Epoch 748, Loss: 0.08093040077278132\n",
      "Epoch 749, Loss: 0.08073753887680775\n",
      "Epoch 750, Loss: 0.08054519953399035\n",
      "Epoch 751, Loss: 0.0803533813284881\n",
      "Epoch 752, Loss: 0.08016208284829603\n",
      "Epoch 753, Loss: 0.07997130268523488\n",
      "Epoch 754, Loss: 0.07978103943494103\n",
      "Epoch 755, Loss: 0.07959129169685582\n",
      "Epoch 756, Loss: 0.07940205807421535\n",
      "Epoch 757, Loss: 0.07921333717404014\n",
      "Epoch 758, Loss: 0.0790251276071251\n",
      "Epoch 759, Loss: 0.07883742798802908\n",
      "Epoch 760, Loss: 0.07865023693506476\n",
      "Epoch 761, Loss: 0.07846355307028831\n",
      "Epoch 762, Loss: 0.07827737501948966\n",
      "Epoch 763, Loss: 0.07809170141218177\n",
      "Epoch 764, Loss: 0.07790653088159133\n",
      "Epoch 765, Loss: 0.0777218620646478\n",
      "Epoch 766, Loss: 0.07753769360197411\n",
      "Epoch 767, Loss: 0.07735402413787643\n",
      "Epoch 768, Loss: 0.07717085232033391\n",
      "Epoch 769, Loss: 0.07698817680098924\n",
      "Epoch 770, Loss: 0.07680599623513812\n",
      "Epoch 771, Loss: 0.07662430928171983\n",
      "Epoch 772, Loss: 0.07644311460330731\n",
      "Epoch 773, Loss: 0.07626241086609713\n",
      "Epoch 774, Loss: 0.07608219673989979\n",
      "Epoch 775, Loss: 0.07590247089812978\n",
      "Epoch 776, Loss: 0.07572323201779602\n",
      "Epoch 777, Loss: 0.07554447877949215\n",
      "Epoch 778, Loss: 0.07536620986738649\n",
      "Epoch 779, Loss: 0.07518842396921258\n",
      "Epoch 780, Loss: 0.07501111977625975\n",
      "Epoch 781, Loss: 0.07483429598336296\n",
      "Epoch 782, Loss: 0.0746579512888936\n",
      "Epoch 783, Loss: 0.07448208439474974\n",
      "Epoch 784, Loss: 0.07430669400634655\n",
      "Epoch 785, Loss: 0.07413177883260715\n",
      "Epoch 786, Loss: 0.0739573375859523\n",
      "Epoch 787, Loss: 0.07378336898229193\n",
      "Epoch 788, Loss: 0.0736098717410147\n",
      "Epoch 789, Loss: 0.0734368445849795\n",
      "Epoch 790, Loss: 0.07326428624050513\n",
      "Epoch 791, Loss: 0.0730921954373618\n",
      "Epoch 792, Loss: 0.07292057090876106\n",
      "Epoch 793, Loss: 0.07274941139134697\n",
      "Epoch 794, Loss: 0.07257871562518649\n",
      "Epoch 795, Loss: 0.0724084823537604\n",
      "Epoch 796, Loss: 0.07223871032395411\n",
      "Epoch 797, Loss: 0.072069398286048\n",
      "Epoch 798, Loss: 0.07190054499370872\n",
      "Epoch 799, Loss: 0.07173214920397987\n",
      "Epoch 800, Loss: 0.0715642096772726\n",
      "Epoch 801, Loss: 0.07139672517735686\n",
      "Epoch 802, Loss: 0.07122969447135208\n",
      "Epoch 803, Loss: 0.0710631163297181\n",
      "Epoch 804, Loss: 0.07089698952624622\n",
      "Epoch 805, Loss: 0.07073131283805004\n",
      "Epoch 806, Loss: 0.07056608504555666\n",
      "Epoch 807, Loss: 0.0704013049324974\n",
      "Epoch 808, Loss: 0.07023697128589913\n",
      "Epoch 809, Loss: 0.07007308289607526\n",
      "Epoch 810, Loss: 0.06990963855661673\n",
      "Epoch 811, Loss: 0.0697466370643833\n",
      "Epoch 812, Loss: 0.06958407721949436\n",
      "Epoch 813, Loss: 0.06942195782532072\n",
      "Epoch 814, Loss: 0.0692602776884751\n",
      "Epoch 815, Loss: 0.06909903561880382\n",
      "Epoch 816, Loss: 0.0689382304293778\n",
      "Epoch 817, Loss: 0.06877786093648405\n",
      "Epoch 818, Loss: 0.0686179259596166\n",
      "Epoch 819, Loss: 0.06845842432146816\n",
      "Epoch 820, Loss: 0.06829935484792136\n",
      "Epoch 821, Loss: 0.0681407163680399\n",
      "Epoch 822, Loss: 0.06798250771406024\n",
      "Epoch 823, Loss: 0.06782472772138277\n",
      "Epoch 824, Loss: 0.06766737522856342\n",
      "Epoch 825, Loss: 0.06751044907730491\n",
      "Epoch 826, Loss: 0.06735394811244841\n",
      "Epoch 827, Loss: 0.0671978711819649\n",
      "Epoch 828, Loss: 0.06704221713694673\n",
      "Epoch 829, Loss: 0.06688698483159929\n",
      "Epoch 830, Loss: 0.06673217312323243\n",
      "Epoch 831, Loss: 0.06657778087225197\n",
      "Epoch 832, Loss: 0.06642380694215151\n",
      "Epoch 833, Loss: 0.06627025019950396\n",
      "Epoch 834, Loss: 0.06611710951395319\n",
      "Epoch 835, Loss: 0.06596438375820589\n",
      "Epoch 836, Loss: 0.0658120718080229\n",
      "Epoch 837, Loss: 0.06566017254221118\n",
      "Epoch 838, Loss: 0.06550868484261571\n",
      "Epoch 839, Loss: 0.0653576075941109\n",
      "Epoch 840, Loss: 0.06520693968459255\n",
      "Epoch 841, Loss: 0.06505668000496988\n",
      "Epoch 842, Loss: 0.06490682744915688\n",
      "Epoch 843, Loss: 0.06475738091406467\n",
      "Epoch 844, Loss: 0.06460833929959295\n",
      "Epoch 845, Loss: 0.06445970150862229\n",
      "Epoch 846, Loss: 0.06431146644700572\n",
      "Epoch 847, Loss: 0.06416363302356096\n",
      "Epoch 848, Loss: 0.06401620015006221\n",
      "Epoch 849, Loss: 0.06386916674123205\n",
      "Epoch 850, Loss: 0.06372253171473388\n",
      "Epoch 851, Loss: 0.06357629399116335\n",
      "Epoch 852, Loss: 0.0634304524940409\n",
      "Epoch 853, Loss: 0.0632850061498036\n",
      "Epoch 854, Loss: 0.0631399538877973\n",
      "Epoch 855, Loss: 0.0629952946402687\n",
      "Epoch 856, Loss: 0.06285102734235772\n",
      "Epoch 857, Loss: 0.06270715093208924\n",
      "Epoch 858, Loss: 0.06256366435036582\n",
      "Epoch 859, Loss: 0.062420566540959316\n",
      "Epoch 860, Loss: 0.062277856450503606\n",
      "Epoch 861, Loss: 0.0621355330284866\n",
      "Epoch 862, Loss: 0.0619935952272424\n",
      "Epoch 863, Loss: 0.06185204200194385\n",
      "Epoch 864, Loss: 0.061710872310594654\n",
      "Epoch 865, Loss: 0.06157008511402188\n",
      "Epoch 866, Loss: 0.06142967937586806\n",
      "Epoch 867, Loss: 0.061289654062583805\n",
      "Epoch 868, Loss: 0.06115000814342016\n",
      "Epoch 869, Loss: 0.06101074059042076\n",
      "Epoch 870, Loss: 0.06087185037841452\n",
      "Epoch 871, Loss: 0.06073333648500816\n",
      "Epoch 872, Loss: 0.06059519789057838\n",
      "Epoch 873, Loss: 0.06045743357826447\n",
      "Epoch 874, Loss: 0.06032004253396109\n",
      "Epoch 875, Loss: 0.060183023746310425\n",
      "Epoch 876, Loss: 0.06004637620669503\n",
      "Epoch 877, Loss: 0.05991009890923016\n",
      "Epoch 878, Loss: 0.0597741908507564\n",
      "Epoch 879, Loss: 0.05963865103083256\n",
      "Epoch 880, Loss: 0.0595034784517281\n",
      "Epoch 881, Loss: 0.05936867211841559\n",
      "Epoch 882, Loss: 0.05923423103856385\n",
      "Epoch 883, Loss: 0.05910015422253025\n",
      "Epoch 884, Loss: 0.058966440683353556\n",
      "Epoch 885, Loss: 0.05883308943674676\n",
      "Epoch 886, Loss: 0.05870009950108961\n",
      "Epoch 887, Loss: 0.05856746989742177\n",
      "Epoch 888, Loss: 0.05843519964943509\n",
      "Epoch 889, Loss: 0.05830328778346688\n",
      "Epoch 890, Loss: 0.05817173332849245\n",
      "Epoch 891, Loss: 0.058040535316118136\n",
      "Epoch 892, Loss: 0.05790969278057401\n",
      "Epoch 893, Loss: 0.057779204758706994\n",
      "Epoch 894, Loss: 0.05764907028997364\n",
      "Epoch 895, Loss: 0.0575192884164329\n",
      "Epoch 896, Loss: 0.05738985818273939\n",
      "Epoch 897, Loss: 0.05726077863613614\n",
      "Epoch 898, Loss: 0.05713204882644769\n",
      "Epoch 899, Loss: 0.05700366780607301\n",
      "Epoch 900, Loss: 0.05687563462997861\n",
      "Epoch 901, Loss: 0.05674794835569142\n",
      "Epoch 902, Loss: 0.056620608043292185\n",
      "Epoch 903, Loss: 0.05649361275540812\n",
      "Epoch 904, Loss: 0.056366961557206274\n",
      "Epoch 905, Loss: 0.0562406535163867\n",
      "Epoch 906, Loss: 0.05611468770317539\n",
      "Epoch 907, Loss: 0.05598906319031758\n",
      "Epoch 908, Loss: 0.05586377905307075\n",
      "Epoch 909, Loss: 0.055738834369198124\n",
      "Epoch 910, Loss: 0.05561422821896162\n",
      "Epoch 911, Loss: 0.055489959685115164\n",
      "Epoch 912, Loss: 0.055366027852897834\n",
      "Epoch 913, Loss: 0.05524243181002741\n",
      "Epoch 914, Loss: 0.05511917064669328\n",
      "Epoch 915, Loss: 0.05499624345554999\n",
      "Epoch 916, Loss: 0.05487364933171059\n",
      "Epoch 917, Loss: 0.054751387372739865\n",
      "Epoch 918, Loss: 0.05462945667864767\n",
      "Epoch 919, Loss: 0.054507856351882385\n",
      "Epoch 920, Loss: 0.05438658549732429\n",
      "Epoch 921, Loss: 0.054265643222278954\n",
      "Epoch 922, Loss: 0.05414502863647057\n",
      "Epoch 923, Loss: 0.054024740852035714\n",
      "Epoch 924, Loss: 0.05390477898351645\n",
      "Epoch 925, Loss: 0.053785142147854\n",
      "Epoch 926, Loss: 0.05366582946438225\n",
      "Epoch 927, Loss: 0.05354684005482112\n",
      "Epoch 928, Loss: 0.05342817304327025\n",
      "Epoch 929, Loss: 0.05330982755620254\n",
      "Epoch 930, Loss: 0.05319180272245767\n",
      "Epoch 931, Loss: 0.053074097673235635\n",
      "Epoch 932, Loss: 0.05295671154209053\n",
      "Epoch 933, Loss: 0.05283964346492398\n",
      "Epoch 934, Loss: 0.052722892579978815\n",
      "Epoch 935, Loss: 0.05260645802783297\n",
      "Epoch 936, Loss: 0.05249033895139263\n",
      "Epoch 937, Loss: 0.05237453449588657\n",
      "Epoch 938, Loss: 0.052259043808859394\n",
      "Epoch 939, Loss: 0.05214386604016535\n",
      "Epoch 940, Loss: 0.05202900034196217\n",
      "Epoch 941, Loss: 0.05191444586870493\n",
      "Epoch 942, Loss: 0.05180020177713952\n",
      "Epoch 943, Loss: 0.05168626722629656\n",
      "Epoch 944, Loss: 0.05157264137748547\n",
      "Epoch 945, Loss: 0.05145932339428782\n",
      "Epoch 946, Loss: 0.05134631244255159\n",
      "Epoch 947, Loss: 0.05123360769038483\n",
      "Epoch 948, Loss: 0.051121208308149625\n",
      "Epoch 949, Loss: 0.05100911346845578\n",
      "Epoch 950, Loss: 0.050897322346155086\n",
      "Epoch 951, Loss: 0.050785834118334906\n",
      "Epoch 952, Loss: 0.050674647964312286\n",
      "Epoch 953, Loss: 0.05056376306562795\n",
      "Epoch 954, Loss: 0.050453178606040185\n",
      "Epoch 955, Loss: 0.050342893771518786\n",
      "Epoch 956, Loss: 0.05023290775023927\n",
      "Epoch 957, Loss: 0.05012321973257657\n",
      "Epoch 958, Loss: 0.05001382891109946\n",
      "Epoch 959, Loss: 0.04990473448056436\n",
      "Epoch 960, Loss: 0.04979593563790942\n",
      "Epoch 961, Loss: 0.049687431582248816\n",
      "Epoch 962, Loss: 0.049579221514866434\n",
      "Epoch 963, Loss: 0.049471304639210505\n",
      "Epoch 964, Loss: 0.049363680160887394\n",
      "Epoch 965, Loss: 0.0492563472876558\n",
      "Epoch 966, Loss: 0.049149305229421084\n",
      "Epoch 967, Loss: 0.04904255319822924\n",
      "Epoch 968, Loss: 0.04893609040826131\n",
      "Epoch 969, Loss: 0.04882991607582738\n",
      "Epoch 970, Loss: 0.0487240294193609\n",
      "Epoch 971, Loss: 0.04861842965941316\n",
      "Epoch 972, Loss: 0.04851311601864708\n",
      "Epoch 973, Loss: 0.0484080877218319\n",
      "Epoch 974, Loss: 0.048303343995837245\n",
      "Epoch 975, Loss: 0.04819888406962762\n",
      "Epoch 976, Loss: 0.04809470717425658\n",
      "Epoch 977, Loss: 0.047990812542861\n",
      "Epoch 978, Loss: 0.04788719941065568\n",
      "Epoch 979, Loss: 0.047783867014927484\n",
      "Epoch 980, Loss: 0.047680814595029986\n",
      "Epoch 981, Loss: 0.04757804139237756\n",
      "Epoch 982, Loss: 0.04747554665044\n",
      "Epoch 983, Loss: 0.0473733296147368\n",
      "Epoch 984, Loss: 0.047271389532831845\n",
      "Epoch 985, Loss: 0.04716972565432765\n",
      "Epoch 986, Loss: 0.04706833723085998\n",
      "Epoch 987, Loss: 0.046967223516092046\n",
      "Epoch 988, Loss: 0.046866383765709466\n",
      "Epoch 989, Loss: 0.04676581723741442\n",
      "Epoch 990, Loss: 0.04666552319092052\n",
      "Epoch 991, Loss: 0.04656550088794692\n",
      "Epoch 992, Loss: 0.04646574959221323\n",
      "Optimal Weights (DGD): [4.86005009 4.33312454]\n",
      "Number of Epochs (DGD): 993\n"
     ]
    }
   ],
   "source": [
    "# Deterministic Gradient Descent (DGD)\n",
    "def deterministic_gradient_descent(X_b, y_true, learning_rate, n_epochs, tol=1e-4):\n",
    "    w = np.random.randn(2, 1)\n",
    "    prev_loss = float('inf')\n",
    "    \n",
    "    for epoch in range(n_epochs):\n",
    "        gradients = -2/m * X_b.T.dot(y_true - X_b.dot(w))\n",
    "        w -= learning_rate * gradients\n",
    "        y_pred = X_b.dot(w)\n",
    "        loss = mse(y_true, y_pred)\n",
    "        print(f\"Epoch {epoch}, Loss: {loss}\")\n",
    "        \n",
    "        # Check convergence based on change in loss\n",
    "        if abs(prev_loss - loss) < tol:\n",
    "            break\n",
    "        \n",
    "        prev_loss = loss\n",
    "    \n",
    "    return w.flatten(), epoch + 1\n",
    "\n",
    "# Run Deterministic Gradient Descent\n",
    "w_dgd, epochs_dgd = deterministic_gradient_descent(X_b, y_true, learning_rate, n_epochs)\n",
    "\n",
    "print(\"Optimal Weights (DGD):\", w_dgd)\n",
    "print(\"Number of Epochs (DGD):\", epochs_dgd)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fc6bedb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal Weights (Direct Gradient Descent): [4.51747803 4.98452148]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Generate synthetic data\n",
    "np.random.seed(42)\n",
    "X = np.random.rand(1000, 1)\n",
    "y_true = 5 * X + 4.5 + 0.1 * np.random.randn(1000, 1)\n",
    "\n",
    "# Add a bias term to X\n",
    "X_b = np.c_[np.ones((1000, 1)), X]\n",
    "\n",
    "# Direct Gradient Descent (Normal Equation)\n",
    "def direct_gradient_descent(X_b, y_true):\n",
    "    \"\"\"\n",
    "    Perform Direct Gradient Descent using the normal equation.\n",
    "\n",
    "    Parameters:\n",
    "    - X_b: Input data with bias term\n",
    "    - y_true: True labels\n",
    "\n",
    "    Returns:\n",
    "    - w: Optimal weights (w0, w1)\n",
    "    \"\"\"\n",
    "    w = np.linalg.inv(X_b.T.dot(X_b)).dot(X_b.T).dot(y_true)\n",
    "    return w.flatten()\n",
    "\n",
    "# Run Direct Gradient Descent\n",
    "w_direct = direct_gradient_descent(X_b, y_true)\n",
    "\n",
    "print(\"Optimal Weights (Direct Gradient Descent):\", w_direct)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b85f1491",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
